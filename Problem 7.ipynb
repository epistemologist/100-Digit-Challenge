{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48HONqnFpIvI"
   },
   "source": [
    "# Problem 7\n",
    "Let $A$ be the $20000 \\times 20000$ matrix whose entries are 0 everywhere except for the primes 2,3,5,7,...,224737 along the main diagonal and the number 1 in all the positions $ a_{ij} $ with $ |i-j| = 1,2,4,8,\\cdots,16384$. What is the (1,1) entry of $A^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiZSIfm1qR-F"
   },
   "source": [
    "### Some introductory code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 1558,
     "status": "ok",
     "timestamp": 1603893832461,
     "user": {
      "displayName": "Husnain Raza",
      "photoUrl": "",
      "userId": "16146658556003895350"
     },
     "user_tz": 300
    },
    "id": "wvpmKjZMqRiB",
    "outputId": "9ad6fbfd-f2b3-4ad4-eca6-97830b9d01b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554466, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def is_prime(N):\n",
    "    return N > 1 and all([N%i != 0 for i in range(2, int(N**0.5+1))])\n",
    "primes = [i for i in range(2,250000) if is_prime(i)][:20000]\n",
    "entries = [(i,i,primes[i]) for i in range(len(primes))]\n",
    "for diff in [2**j for j in range(15)]:\n",
    "    for i in range(20000):\n",
    "        j1, j2 = i+diff, i-diff\n",
    "        if 0<=j1<20000: entries.append((i,j1,1))\n",
    "        if 0<=j2<20000: entries.append((i,j2,1))\n",
    "entries = np.array(entries)\n",
    "print(entries.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsdtHzxT3WQc"
   },
   "source": [
    "### Attempt 1: Using standard libraries\n",
    "\n",
    "We avoid calculating $A^{-1}$ explicitly. Instead, note that if we have $\\hat{v}$ be the first column of $ A^{-1} $, then we get that $ A \\hat{v} = (1,0,\\cdots, 0)^{T}$. Let's solve this system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "executionInfo": {
     "elapsed": 789,
     "status": "error",
     "timestamp": 1603893823785,
     "user": {
      "displayName": "Husnain Raza",
      "photoUrl": "",
      "userId": "16146658556003895350"
     },
     "user_tz": 300
    },
    "id": "3QZE1MQao2Zz",
    "outputId": "91fb2579-b63b-4656-d445-18ff6f771c42"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "row, col, data = entries[:, 0], entries[:, 1], entries[:, 2]\n",
    "\n",
    "A = coo_matrix((data, (row, col))).tocsc()\n",
    "b = np.zeros(A.shape[0])\n",
    "b[0] = 1\n",
    "# v = spsolve(A,b)\n",
    "# Timeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NsvKncT7ibZS"
   },
   "source": [
    "The above code times out - so instead, let's try to use an iterative method to solve this linear system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 13545,
     "status": "ok",
     "timestamp": 1603894098393,
     "user": {
      "displayName": "Husnain Raza",
      "photoUrl": "",
      "userId": "16146658556003895350"
     },
     "user_tz": 300
    },
    "id": "NjRjx9eWr4C7",
    "outputId": "df01ffbf-12b1-42b3-8826-607105d1f96a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10: current val = 0.5160474805069852\n",
      "Iteration 20: current val = 0.5424188205227113\n",
      "Iteration 30: current val = 0.5649984704641765\n",
      "Iteration 40: current val = 0.5809367071267324\n",
      "Iteration 50: current val = 0.6096730237142656\n",
      "Iteration 60: current val = 0.6190393486130085\n",
      "Iteration 70: current val = 0.6263245512238234\n",
      "Iteration 80: current val = 0.6508621776392641\n",
      "Iteration 90: current val = 0.6577928020000656\n",
      "Iteration 100: current val = 0.6608853920165397\n",
      "Iteration 110: current val = 0.6646370853741161\n",
      "Iteration 120: current val = 0.6769767188475972\n",
      "Iteration 130: current val = 0.686598661153931\n",
      "Iteration 140: current val = 0.6950283972972651\n",
      "Iteration 150: current val = 0.6985776576929462\n",
      "Iteration 160: current val = 0.700549226696957\n",
      "Iteration 170: current val = 0.7016993660417654\n",
      "Iteration 180: current val = 0.7037530670049756\n",
      "Iteration 190: current val = 0.70578202448334\n",
      "Iteration 200: current val = 0.7080325880243894\n",
      "Iteration 210: current val = 0.7107390862052434\n",
      "Iteration 220: current val = 0.7131266080608784\n",
      "Iteration 230: current val = 0.7154864307143483\n",
      "Iteration 240: current val = 0.7169760206590395\n",
      "Iteration 250: current val = 0.7177222840589774\n",
      "Iteration 260: current val = 0.7182998666211887\n",
      "Iteration 270: current val = 0.7189625336279692\n",
      "Iteration 280: current val = 0.7195270338881113\n",
      "Iteration 290: current val = 0.7198970070328818\n",
      "Iteration 300: current val = 0.7202715787882576\n",
      "Iteration 310: current val = 0.720548747555294\n",
      "Iteration 320: current val = 0.7208623428688858\n",
      "Iteration 330: current val = 0.7211885297932319\n",
      "Iteration 340: current val = 0.7216667311611941\n",
      "Iteration 350: current val = 0.7219940973832849\n",
      "Iteration 360: current val = 0.7224389483334973\n",
      "Iteration 370: current val = 0.7228169933348944\n",
      "Iteration 380: current val = 0.7231983252626363\n",
      "Iteration 390: current val = 0.7234404924750876\n",
      "Iteration 400: current val = 0.7236478043297795\n",
      "Iteration 410: current val = 0.7238808716336398\n",
      "Iteration 420: current val = 0.7241166500666772\n",
      "Iteration 430: current val = 0.7243659045725263\n",
      "Iteration 440: current val = 0.7244940472057783\n",
      "Iteration 450: current val = 0.724633608525676\n",
      "Iteration 460: current val = 0.7247020541105452\n",
      "Iteration 470: current val = 0.7247680447799154\n",
      "Iteration 480: current val = 0.7248237539591655\n",
      "Iteration 490: current val = 0.7248677969693484\n",
      "Iteration 500: current val = 0.7248916848307266\n",
      "Iteration 510: current val = 0.7249208479337073\n",
      "Iteration 520: current val = 0.7249533593512273\n",
      "Iteration 530: current val = 0.7249736254056114\n",
      "Iteration 540: current val = 0.7249887123438771\n",
      "Iteration 550: current val = 0.7250067816490801\n",
      "Iteration 560: current val = 0.7250207131481929\n",
      "Iteration 570: current val = 0.7250304954206683\n",
      "Iteration 580: current val = 0.7250427286641773\n",
      "Iteration 590: current val = 0.72505125564296\n",
      "Iteration 600: current val = 0.7250561238493789\n",
      "Iteration 610: current val = 0.7250605939852699\n",
      "Iteration 620: current val = 0.7250640020707945\n",
      "Iteration 630: current val = 0.7250660938618454\n",
      "Iteration 640: current val = 0.7250677953689088\n",
      "Iteration 650: current val = 0.7250693490905185\n",
      "Iteration 660: current val = 0.725070446117053\n",
      "Iteration 670: current val = 0.7250713225273709\n",
      "Iteration 680: current val = 0.7250726985038631\n",
      "Iteration 690: current val = 0.7250739362881828\n",
      "Iteration 700: current val = 0.7250748779230066\n",
      "Iteration 710: current val = 0.7250755450783181\n",
      "Iteration 720: current val = 0.7250760283885833\n",
      "Iteration 730: current val = 0.7250765020947028\n",
      "Iteration 740: current val = 0.7250770006680382\n",
      "Iteration 750: current val = 0.7250773496606184\n",
      "Iteration 760: current val = 0.7250776006228311\n",
      "Iteration 770: current val = 0.7250777636744249\n",
      "Iteration 780: current val = 0.7250778756720382\n",
      "Iteration 790: current val = 0.7250779688442739\n",
      "Iteration 800: current val = 0.7250780439687791\n",
      "Iteration 810: current val = 0.7250781067493376\n",
      "Iteration 820: current val = 0.7250781516265811\n",
      "Iteration 830: current val = 0.7250781883759363\n",
      "Iteration 840: current val = 0.7250782241898078\n",
      "Iteration 850: current val = 0.7250782614326434\n",
      "Iteration 860: current val = 0.7250782837700643\n",
      "Iteration 870: current val = 0.7250782994297919\n",
      "Iteration 880: current val = 0.7250783112476437\n",
      "Iteration 890: current val = 0.7250783221719436\n",
      "Iteration 900: current val = 0.725078329800566\n",
      "Iteration 910: current val = 0.7250783351385289\n",
      "Iteration 920: current val = 0.7250783385028293\n",
      "Iteration 930: current val = 0.7250783410043907\n",
      "Iteration 940: current val = 0.725078342638123\n",
      "Iteration 950: current val = 0.7250783438331366\n",
      "Iteration 960: current val = 0.7250783446050801\n",
      "Iteration 970: current val = 0.7250783450804342\n",
      "Iteration 980: current val = 0.7250783453953678\n",
      "Iteration 990: current val = 0.725078345614237\n",
      "Iteration 1000: current val = 0.7250783457924285\n",
      "Iteration 1010: current val = 0.7250783459042496\n",
      "Iteration 1020: current val = 0.7250783459839163\n",
      "Iteration 1030: current val = 0.7250783460699098\n",
      "Iteration 1040: current val = 0.7250783461385248\n",
      "Iteration 1050: current val = 0.7250783461804372\n",
      "Iteration 1060: current val = 0.7250783462047834\n",
      "Iteration 1070: current val = 0.7250783462184939\n",
      "Iteration 1080: current val = 0.7250783462318636\n",
      "Iteration 1090: current val = 0.7250783462415041\n",
      "Iteration 1100: current val = 0.7250783462487344\n",
      "Iteration 1110: current val = 0.7250783462541678\n",
      "Iteration 1120: current val = 0.7250783462581615\n",
      "Iteration 1130: current val = 0.72507834626106\n",
      "Iteration 1140: current val = 0.725078346263089\n",
      "Iteration 1150: current val = 0.72507834626454\n",
      "Iteration 1160: current val = 0.7250783462657099\n",
      "Iteration 1170: current val = 0.7250783462665752\n",
      "Iteration 1180: current val = 0.7250783462671782\n",
      "Iteration 1190: current val = 0.7250783462676181\n",
      "Iteration 1200: current val = 0.7250783462679155\n",
      "Iteration 1210: current val = 0.7250783462681067\n",
      "Iteration 1220: current val = 0.7250783462682162\n",
      "Iteration 1230: current val = 0.7250783462682798\n",
      "Iteration 1240: current val = 0.7250783462683179\n",
      "Iteration 1250: current val = 0.725078346268345\n",
      "Iteration 1260: current val = 0.7250783462683673\n",
      "Iteration 1270: current val = 0.7250783462683824\n",
      "Iteration 1280: current val = 0.7250783462683897\n",
      "Iteration 1290: current val = 0.7250783462683944\n",
      "Iteration 1300: current val = 0.7250783462683967\n",
      "Iteration 1310: current val = 0.7250783462683981\n",
      "Iteration 1320: current val = 0.7250783462683992\n",
      "Iteration 1330: current val = 0.7250783462684001\n",
      "Iteration 1340: current val = 0.7250783462684001\n",
      "Iteration 1350: current val = 0.7250783462684001\n",
      "Iteration 1360: current val = 0.7250783462684001\n",
      "Iteration 1370: current val = 0.7250783462684001\n",
      "Iteration 1380: current val = 0.7250783462684001\n",
      "Iteration 1390: current val = 0.7250783462684001\n",
      "Iteration 1400: current val = 0.7250783462684001\n",
      "Iteration 1410: current val = 0.7250783462684001\n",
      "Iteration 1420: current val = 0.7250783462684001\n",
      "Iteration 1430: current val = 0.7250783462684001\n",
      "Iteration 1440: current val = 0.7250783462684001\n",
      "Iteration 1450: current val = 0.7250783462684001\n",
      "Iteration 1460: current val = 0.7250783462684001\n",
      "Iteration 1470: current val = 0.7250783462684001\n",
      "Iteration 1480: current val = 0.7250783462684001\n",
      "Iteration 1490: current val = 0.7250783462684001\n",
      "Iteration 1500: current val = 0.7250783462684001\n",
      "Iteration 1510: current val = 0.7250783462684001\n",
      "Iteration 1520: current val = 0.7250783462684001\n",
      "Iteration 1530: current val = 0.7250783462684001\n",
      "Iteration 1540: current val = 0.7250783462684001\n",
      "Iteration 1550: current val = 0.7250783462684001\n",
      "Iteration 1560: current val = 0.7250783462684001\n",
      "Iteration 1570: current val = 0.7250783462684001\n",
      "Iteration 1580: current val = 0.7250783462684001\n",
      "Iteration 1590: current val = 0.7250783462684001\n",
      "Iteration 1600: current val = 0.7250783462684001\n",
      "Iteration 1610: current val = 0.7250783462684001\n",
      "Iteration 1620: current val = 0.7250783462684001\n",
      "Iteration 1630: current val = 0.7250783462684001\n",
      "Iteration 1640: current val = 0.7250783462684001\n",
      "Iteration 1650: current val = 0.7250783462684001\n",
      "Iteration 1660: current val = 0.7250783462684001\n",
      "Iteration 1670: current val = 0.7250783462684001\n",
      "Iteration 1680: current val = 0.7250783462684001\n",
      "Iteration 1690: current val = 0.7250783462684001\n",
      "Iteration 1700: current val = 0.7250783462684001\n",
      "Iteration 1710: current val = 0.7250783462684001\n",
      "Iteration 1720: current val = 0.7250783462684001\n",
      "Iteration 1730: current val = 0.7250783462684001\n",
      "Iteration 1740: current val = 0.7250783462684001\n",
      "Iteration 1750: current val = 0.7250783462684001\n",
      "Iteration 1760: current val = 0.7250783462684001\n",
      "Iteration 1770: current val = 0.7250783462684001\n",
      "Iteration 1780: current val = 0.7250783462684001\n",
      "Iteration 1790: current val = 0.7250783462684001\n",
      "Iteration 1800: current val = 0.7250783462684001\n",
      "Iteration 1810: current val = 0.7250783462684001\n",
      "Iteration 1820: current val = 0.7250783462684001\n",
      "Iteration 1830: current val = 0.7250783462684001\n",
      "Iteration 1840: current val = 0.7250783462684001\n",
      "Iteration 1850: current val = 0.7250783462684001\n",
      "Iteration 1860: current val = 0.7250783462684001\n",
      "Iteration 1870: current val = 0.7250783462684001\n",
      "Iteration 1880: current val = 0.7250783462684001\n",
      "Iteration 1890: current val = 0.7250783462684001\n",
      "Iteration 1900: current val = 0.7250783462684001\n",
      "Iteration 1910: current val = 0.7250783462684001\n",
      "Iteration 1920: current val = 0.7250783462684001\n",
      "Iteration 1930: current val = 0.7250783462684001\n",
      "Iteration 1940: current val = 0.7250783462684001\n",
      "Iteration 1950: current val = 0.7250783462684001\n",
      "Iteration 1960: current val = 0.7250783462684001\n",
      "Iteration 1970: current val = 0.7250783462684001\n",
      "Iteration 1980: current val = 0.7250783462684001\n",
      "Iteration 1990: current val = 0.7250783462684001\n",
      "Iteration 2000: current val = 0.7250783462684001\n",
      "Iteration 2010: current val = 0.7250783462684001\n",
      "Iteration 2020: current val = 0.7250783462684001\n",
      "Iteration 2030: current val = 0.7250783462684001\n",
      "Iteration 2040: current val = 0.7250783462684001\n",
      "Iteration 2050: current val = 0.7250783462684001\n",
      "Iteration 2060: current val = 0.7250783462684001\n",
      "Iteration 2070: current val = 0.7250783462684001\n",
      "Iteration 2080: current val = 0.7250783462684001\n",
      "Iteration 2090: current val = 0.7250783462684001\n",
      "Iteration 2100: current val = 0.7250783462684001\n",
      "Iteration 2110: current val = 0.7250783462684001\n",
      "Iteration 2120: current val = 0.7250783462684001\n",
      "Iteration 2130: current val = 0.7250783462684001\n",
      "Iteration 2140: current val = 0.7250783462684001\n",
      "Iteration 2150: current val = 0.7250783462684001\n",
      "Iteration 2160: current val = 0.7250783462684001\n",
      "Iteration 2170: current val = 0.7250783462684001\n",
      "Iteration 2180: current val = 0.7250783462684001\n",
      "Iteration 2190: current val = 0.7250783462684001\n",
      "Iteration 2200: current val = 0.7250783462684001\n",
      "Iteration 2210: current val = 0.7250783462684001\n",
      "Iteration 2220: current val = 0.7250783462684001\n",
      "Iteration 2230: current val = 0.7250783462684001\n",
      "Iteration 2240: current val = 0.7250783462684001\n",
      "Iteration 2250: current val = 0.7250783462684001\n",
      "Iteration 2260: current val = 0.7250783462684001\n",
      "Iteration 2270: current val = 0.7250783462684001\n",
      "Iteration 2280: current val = 0.7250783462684001\n",
      "Iteration 2290: current val = 0.7250783462684001\n",
      "0.7250783462684001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse.linalg import bicg\n",
    "row = np.array([i[0] for i in entries])\n",
    "col = np.array([i[1] for i in entries])\n",
    "data = np.array([i[2] for i in entries])\n",
    "\n",
    "A = coo_matrix((data, (row, col))).tocsc()\n",
    "b = np.zeros(A.shape[0])\n",
    "b[0] = 1\n",
    "\n",
    "iterations = 0\n",
    "def callback(xk):\n",
    "    global iterations\n",
    "    iterations += 1\n",
    "    if iterations % 10 == 0: print(\"Iteration {}: current val = {}\".format(iterations, xk[0]))\n",
    "x, exit_code = bicg(A,b,tol=1e-50,callback=callback)\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QWXAQN7K6gH7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 11,\n",
       " 13,\n",
       " 17,\n",
       " 19,\n",
       " 23,\n",
       " 29,\n",
       " 31,\n",
       " 37,\n",
       " 41,\n",
       " 43,\n",
       " 47,\n",
       " 53,\n",
       " 59,\n",
       " 61,\n",
       " 67,\n",
       " 71,\n",
       " 73,\n",
       " 79,\n",
       " 83,\n",
       " 89,\n",
       " 97]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_prime(N):\n",
    "    return N > 1 and all([N%i != 0 for i in range(2, int(N**0.5+1))])\n",
    "\n",
    "[i for i in range(100) if is_prime(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(554466, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20000x20000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 554466 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package scipy.sparse.linalg in scipy.sparse:\n",
      "\n",
      "NAME\n",
      "    scipy.sparse.linalg\n",
      "\n",
      "DESCRIPTION\n",
      "    Sparse linear algebra (:mod:`scipy.sparse.linalg`)\n",
      "    ==================================================\n",
      "    \n",
      "    .. currentmodule:: scipy.sparse.linalg\n",
      "    \n",
      "    Abstract linear operators\n",
      "    -------------------------\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       LinearOperator -- abstract representation of a linear operator\n",
      "       aslinearoperator -- convert an object to an abstract linear operator\n",
      "    \n",
      "    Matrix Operations\n",
      "    -----------------\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       inv -- compute the sparse matrix inverse\n",
      "       expm -- compute the sparse matrix exponential\n",
      "       expm_multiply -- compute the product of a matrix exponential and a matrix\n",
      "    \n",
      "    Matrix norms\n",
      "    ------------\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       norm -- Norm of a sparse matrix\n",
      "       onenormest -- Estimate the 1-norm of a sparse matrix\n",
      "    \n",
      "    Solving linear problems\n",
      "    -----------------------\n",
      "    \n",
      "    Direct methods for linear equation systems:\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       spsolve -- Solve the sparse linear system Ax=b\n",
      "       spsolve_triangular -- Solve the sparse linear system Ax=b for a triangular matrix\n",
      "       factorized -- Pre-factorize matrix to a function solving a linear system\n",
      "       MatrixRankWarning -- Warning on exactly singular matrices\n",
      "       use_solver -- Select direct solver to use\n",
      "    \n",
      "    Iterative methods for linear equation systems:\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       bicg -- Use BIConjugate Gradient iteration to solve A x = b\n",
      "       bicgstab -- Use BIConjugate Gradient STABilized iteration to solve A x = b\n",
      "       cg -- Use Conjugate Gradient iteration to solve A x = b\n",
      "       cgs -- Use Conjugate Gradient Squared iteration to solve A x = b\n",
      "       gmres -- Use Generalized Minimal RESidual iteration to solve A x = b\n",
      "       lgmres -- Solve a matrix equation using the LGMRES algorithm\n",
      "       minres -- Use MINimum RESidual iteration to solve Ax = b\n",
      "       qmr -- Use Quasi-Minimal Residual iteration to solve A x = b\n",
      "       gcrotmk -- Solve a matrix equation using the GCROT(m,k) algorithm\n",
      "       tfqmr -- Use Transpose-Free Quasi-Minimal Residual iteration to solve A x = b\n",
      "    \n",
      "    Iterative methods for least-squares problems:\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       lsqr -- Find the least-squares solution to a sparse linear equation system\n",
      "       lsmr -- Find the least-squares solution to a sparse linear equation system\n",
      "    \n",
      "    Matrix factorizations\n",
      "    ---------------------\n",
      "    \n",
      "    Eigenvalue problems:\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       eigs -- Find k eigenvalues and eigenvectors of the square matrix A\n",
      "       eigsh -- Find k eigenvalues and eigenvectors of a symmetric matrix\n",
      "       lobpcg -- Solve symmetric partial eigenproblems with optional preconditioning\n",
      "    \n",
      "    Singular values problems:\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       svds -- Compute k singular values/vectors for a sparse matrix\n",
      "    \n",
      "    The `svds` function supports the following solvers:\n",
      "    \n",
      "    .. toctree::\n",
      "    \n",
      "        sparse.linalg.svds-arpack\n",
      "        sparse.linalg.svds-lobpcg\n",
      "        sparse.linalg.svds-propack\n",
      "    \n",
      "    Complete or incomplete LU factorizations\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       splu -- Compute a LU decomposition for a sparse matrix\n",
      "       spilu -- Compute an incomplete LU decomposition for a sparse matrix\n",
      "       SuperLU -- Object representing an LU factorization\n",
      "    \n",
      "    Exceptions\n",
      "    ----------\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       ArpackNoConvergence\n",
      "       ArpackError\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _dsolve (package)\n",
      "    _eigen (package)\n",
      "    _expm_multiply\n",
      "    _interface\n",
      "    _isolve (package)\n",
      "    _matfuncs\n",
      "    _norm\n",
      "    _onenormest\n",
      "    _svdp\n",
      "    dsolve\n",
      "    eigen\n",
      "    interface\n",
      "    isolve\n",
      "    matfuncs\n",
      "    tests (package)\n",
      "\n",
      "CLASSES\n",
      "    builtins.RuntimeError(builtins.Exception)\n",
      "        scipy.sparse.linalg._eigen.arpack.arpack.ArpackError\n",
      "            scipy.sparse.linalg._eigen.arpack.arpack.ArpackNoConvergence\n",
      "    builtins.UserWarning(builtins.Warning)\n",
      "        scipy.sparse.linalg._dsolve.linsolve.MatrixRankWarning\n",
      "    builtins.object\n",
      "        builtins.SuperLU\n",
      "        scipy.sparse.linalg._interface.LinearOperator\n",
      "    \n",
      "    class ArpackError(builtins.RuntimeError)\n",
      "     |  ArpackError(info, infodict={'d': {0: 'Normal exit.', 1: 'Maximum number of iterations taken. All possible eigenvalues of OP has been found. IPARAM(5) returns the number of wanted converged Ritz values.', 2: 'No longer an informational error. Deprecated starting with release 2 of ARPACK.', 3: 'No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ', -1: 'N must be positive.', -2: 'NEV must be positive.', -3: 'NCV-NEV >= 2 and less than or equal to N.', -4: 'The maximum number of Arnoldi update iterations allowed must be greater than zero.', -5: \" WHICH must be one of 'LM', 'SM', 'LR', 'SR', 'LI', 'SI'\", -6: \"BMAT must be one of 'I' or 'G'.\", -7: 'Length of private work array WORKL is not sufficient.', -8: 'Error return from LAPACK eigenvalue calculation;', -9: 'Starting vector is zero.', -10: 'IPARAM(7) must be 1,2,3,4.', -11: \"IPARAM(7) = 1 and BMAT = 'G' are incompatible.\", -12: 'IPARAM(1) must be equal to 0 or 1.', -13: \"NEV and WHICH = 'BE' are incompatible.\", -9999: 'Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated.'}, 's': {0: 'Normal exit.', 1: 'Maximum number of iterations taken. All possible eigenvalues of OP has been found. IPARAM(5) returns the number of wanted converged Ritz values.', 2: 'No longer an informational error. Deprecated starting with release 2 of ARPACK.', 3: 'No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ', -1: 'N must be positive.', -2: 'NEV must be positive.', -3: 'NCV-NEV >= 2 and less than or equal to N.', -4: 'The maximum number of Arnoldi update iterations allowed must be greater than zero.', -5: \" WHICH must be one of 'LM', 'SM', 'LR', 'SR', 'LI', 'SI'\", -6: \"BMAT must be one of 'I' or 'G'.\", -7: 'Length of private work array WORKL is not sufficient.', -8: 'Error return from LAPACK eigenvalue calculation;', -9: 'Starting vector is zero.', -10: 'IPARAM(7) must be 1,2,3,4.', -11: \"IPARAM(7) = 1 and BMAT = 'G' are incompatible.\", -12: 'IPARAM(1) must be equal to 0 or 1.', -13: \"NEV and WHICH = 'BE' are incompatible.\", -9999: 'Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated.'}, 'z': {0: 'Normal exit.', 1: 'Maximum number of iterations taken. All possible eigenvalues of OP has been found. IPARAM(5) returns the number of wanted converged Ritz values.', 2: 'No longer an informational error. Deprecated starting with release 2 of ARPACK.', 3: 'No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ', -1: 'N must be positive.', -2: 'NEV must be positive.', -3: 'NCV-NEV >= 2 and less than or equal to N.', -4: 'The maximum number of Arnoldi update iterations allowed must be greater than zero.', -5: \" WHICH must be one of 'LM', 'SM', 'LR', 'SR', 'LI', 'SI'\", -6: \"BMAT must be one of 'I' or 'G'.\", -7: 'Length of private work array WORKL is not sufficient.', -8: 'Error return from LAPACK eigenvalue calculation;', -9: 'Starting vector is zero.', -10: 'IPARAM(7) must be 1,2,3.', -11: \"IPARAM(7) = 1 and BMAT = 'G' are incompatible.\", -12: 'IPARAM(1) must be equal to 0 or 1.', -13: \"NEV and WHICH = 'BE' are incompatible.\", -9999: 'Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated.'}, 'c': {0: 'Normal exit.', 1: 'Maximum number of iterations taken. All possible eigenvalues of OP has been found. IPARAM(5) returns the number of wanted converged Ritz values.', 2: 'No longer an informational error. Deprecated starting with release 2 of ARPACK.', 3: 'No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ', -1: 'N must be positive.', -2: 'NEV must be positive.', -3: 'NCV-NEV >= 2 and less than or equal to N.', -4: 'The maximum number of Arnoldi update iterations allowed must be greater than zero.', -5: \" WHICH must be one of 'LM', 'SM', 'LR', 'SR', 'LI', 'SI'\", -6: \"BMAT must be one of 'I' or 'G'.\", -7: 'Length of private work array WORKL is not sufficient.', -8: 'Error return from LAPACK eigenvalue calculation;', -9: 'Starting vector is zero.', -10: 'IPARAM(7) must be 1,2,3.', -11: \"IPARAM(7) = 1 and BMAT = 'G' are incompatible.\", -12: 'IPARAM(1) must be equal to 0 or 1.', -13: \"NEV and WHICH = 'BE' are incompatible.\", -9999: 'Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated.'}})\n",
      "     |  \n",
      "     |  ARPACK error\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ArpackError\n",
      "     |      builtins.RuntimeError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, info, infodict={'d': {0: 'Normal exit.', 1: 'Maximum number of iterations taken. All possible eigenvalues of OP has been found. IPARAM(5) returns the number of wanted converged Ritz values.', 2: 'No longer an informational error. Deprecated starting with release 2 of ARPACK.', 3: 'No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ', -1: 'N must be positive.', -2: 'NEV must be positive.', -3: 'NCV-NEV >= 2 and less than or equal to N.', -4: 'The maximum number of Arnoldi update iterations allowed must be greater than zero.', -5: \" WHICH must be one of 'LM', 'SM', 'LR', 'SR', 'LI', 'SI'\", -6: \"BMAT must be one of 'I' or 'G'.\", -7: 'Length of private work array WORKL is not sufficient.', -8: 'Error return from LAPACK eigenvalue calculation;', -9: 'Starting vector is zero.', -10: 'IPARAM(7) must be 1,2,3,4.', -11: \"IPARAM(7) = 1 and BMAT = 'G' are incompatible.\", -12: 'IPARAM(1) must be equal to 0 or 1.', -13: \"NEV and WHICH = 'BE' are incompatible.\", -9999: 'Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated.'}, 's': {0: 'Normal exit.', 1: 'Maximum number of iterations taken. All possible eigenvalues of OP has been found. IPARAM(5) returns the number of wanted converged Ritz values.', 2: 'No longer an informational error. Deprecated starting with release 2 of ARPACK.', 3: 'No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ', -1: 'N must be positive.', -2: 'NEV must be positive.', -3: 'NCV-NEV >= 2 and less than or equal to N.', -4: 'The maximum number of Arnoldi update iterations allowed must be greater than zero.', -5: \" WHICH must be one of 'LM', 'SM', 'LR', 'SR', 'LI', 'SI'\", -6: \"BMAT must be one of 'I' or 'G'.\", -7: 'Length of private work array WORKL is not sufficient.', -8: 'Error return from LAPACK eigenvalue calculation;', -9: 'Starting vector is zero.', -10: 'IPARAM(7) must be 1,2,3,4.', -11: \"IPARAM(7) = 1 and BMAT = 'G' are incompatible.\", -12: 'IPARAM(1) must be equal to 0 or 1.', -13: \"NEV and WHICH = 'BE' are incompatible.\", -9999: 'Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated.'}, 'z': {0: 'Normal exit.', 1: 'Maximum number of iterations taken. All possible eigenvalues of OP has been found. IPARAM(5) returns the number of wanted converged Ritz values.', 2: 'No longer an informational error. Deprecated starting with release 2 of ARPACK.', 3: 'No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ', -1: 'N must be positive.', -2: 'NEV must be positive.', -3: 'NCV-NEV >= 2 and less than or equal to N.', -4: 'The maximum number of Arnoldi update iterations allowed must be greater than zero.', -5: \" WHICH must be one of 'LM', 'SM', 'LR', 'SR', 'LI', 'SI'\", -6: \"BMAT must be one of 'I' or 'G'.\", -7: 'Length of private work array WORKL is not sufficient.', -8: 'Error return from LAPACK eigenvalue calculation;', -9: 'Starting vector is zero.', -10: 'IPARAM(7) must be 1,2,3.', -11: \"IPARAM(7) = 1 and BMAT = 'G' are incompatible.\", -12: 'IPARAM(1) must be equal to 0 or 1.', -13: \"NEV and WHICH = 'BE' are incompatible.\", -9999: 'Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated.'}, 'c': {0: 'Normal exit.', 1: 'Maximum number of iterations taken. All possible eigenvalues of OP has been found. IPARAM(5) returns the number of wanted converged Ritz values.', 2: 'No longer an informational error. Deprecated starting with release 2 of ARPACK.', 3: 'No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. ', -1: 'N must be positive.', -2: 'NEV must be positive.', -3: 'NCV-NEV >= 2 and less than or equal to N.', -4: 'The maximum number of Arnoldi update iterations allowed must be greater than zero.', -5: \" WHICH must be one of 'LM', 'SM', 'LR', 'SR', 'LI', 'SI'\", -6: \"BMAT must be one of 'I' or 'G'.\", -7: 'Length of private work array WORKL is not sufficient.', -8: 'Error return from LAPACK eigenvalue calculation;', -9: 'Starting vector is zero.', -10: 'IPARAM(7) must be 1,2,3.', -11: \"IPARAM(7) = 1 and BMAT = 'G' are incompatible.\", -12: 'IPARAM(1) must be equal to 0 or 1.', -13: \"NEV and WHICH = 'BE' are incompatible.\", -9999: 'Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated.'}})\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.RuntimeError:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class ArpackNoConvergence(ArpackError)\n",
      "     |  ArpackNoConvergence(msg, eigenvalues, eigenvectors)\n",
      "     |  \n",
      "     |  ARPACK iteration did not converge\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  eigenvalues : ndarray\n",
      "     |      Partial result. Converged eigenvalues.\n",
      "     |  eigenvectors : ndarray\n",
      "     |      Partial result. Converged eigenvectors.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ArpackNoConvergence\n",
      "     |      ArpackError\n",
      "     |      builtins.RuntimeError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, msg, eigenvalues, eigenvectors)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ArpackError:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.RuntimeError:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class LinearOperator(builtins.object)\n",
      "     |  LinearOperator(*args, **kwargs)\n",
      "     |  \n",
      "     |  Common interface for performing matrix vector products\n",
      "     |  \n",
      "     |  Many iterative methods (e.g. cg, gmres) do not need to know the\n",
      "     |  individual entries of a matrix to solve a linear system A*x=b.\n",
      "     |  Such solvers only require the computation of matrix vector\n",
      "     |  products, A*v where v is a dense vector.  This class serves as\n",
      "     |  an abstract interface between iterative solvers and matrix-like\n",
      "     |  objects.\n",
      "     |  \n",
      "     |  To construct a concrete LinearOperator, either pass appropriate\n",
      "     |  callables to the constructor of this class, or subclass it.\n",
      "     |  \n",
      "     |  A subclass must implement either one of the methods ``_matvec``\n",
      "     |  and ``_matmat``, and the attributes/properties ``shape`` (pair of\n",
      "     |  integers) and ``dtype`` (may be None). It may call the ``__init__``\n",
      "     |  on this class to have these attributes validated. Implementing\n",
      "     |  ``_matvec`` automatically implements ``_matmat`` (using a naive\n",
      "     |  algorithm) and vice-versa.\n",
      "     |  \n",
      "     |  Optionally, a subclass may implement ``_rmatvec`` or ``_adjoint``\n",
      "     |  to implement the Hermitian adjoint (conjugate transpose). As with\n",
      "     |  ``_matvec`` and ``_matmat``, implementing either ``_rmatvec`` or\n",
      "     |  ``_adjoint`` implements the other automatically. Implementing\n",
      "     |  ``_adjoint`` is preferable; ``_rmatvec`` is mostly there for\n",
      "     |  backwards compatibility.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  shape : tuple\n",
      "     |      Matrix dimensions (M, N).\n",
      "     |  matvec : callable f(v)\n",
      "     |      Returns returns A * v.\n",
      "     |  rmatvec : callable f(v)\n",
      "     |      Returns A^H * v, where A^H is the conjugate transpose of A.\n",
      "     |  matmat : callable f(V)\n",
      "     |      Returns A * V, where V is a dense matrix with dimensions (N, K).\n",
      "     |  dtype : dtype\n",
      "     |      Data type of the matrix.\n",
      "     |  rmatmat : callable f(V)\n",
      "     |      Returns A^H * V, where V is a dense matrix with dimensions (M, K).\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  args : tuple\n",
      "     |      For linear operators describing products etc. of other linear\n",
      "     |      operators, the operands of the binary operation.\n",
      "     |  ndim : int\n",
      "     |      Number of dimensions (this is always 2)\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  aslinearoperator : Construct LinearOperators\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The user-defined matvec() function must properly handle the case\n",
      "     |  where v has shape (N,) as well as the (N,1) case.  The shape of\n",
      "     |  the return type is handled internally by LinearOperator.\n",
      "     |  \n",
      "     |  LinearOperator instances can also be multiplied, added with each\n",
      "     |  other and exponentiated, all lazily: the result of these operations\n",
      "     |  is always a new, composite LinearOperator, that defers linear\n",
      "     |  operations to the original operators and combines the results.\n",
      "     |  \n",
      "     |  More details regarding how to subclass a LinearOperator and several\n",
      "     |  examples of concrete LinearOperator instances can be found in the\n",
      "     |  external project `PyLops <https://pylops.readthedocs.io>`_.\n",
      "     |  \n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from scipy.sparse.linalg import LinearOperator\n",
      "     |  >>> def mv(v):\n",
      "     |  ...     return np.array([2*v[0], 3*v[1]])\n",
      "     |  ...\n",
      "     |  >>> A = LinearOperator((2,2), matvec=mv)\n",
      "     |  >>> A\n",
      "     |  <2x2 _CustomLinearOperator with dtype=float64>\n",
      "     |  >>> A.matvec(np.ones(2))\n",
      "     |  array([ 2.,  3.])\n",
      "     |  >>> A * np.ones(2)\n",
      "     |  array([ 2.,  3.])\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __add__(self, x)\n",
      "     |  \n",
      "     |  __call__(self, x)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  __init__(self, dtype, shape)\n",
      "     |      Initialize this LinearOperator.\n",
      "     |      \n",
      "     |      To be called by subclasses. ``dtype`` may be None; ``shape`` should\n",
      "     |      be convertible to a length-2 tuple.\n",
      "     |  \n",
      "     |  __matmul__(self, other)\n",
      "     |  \n",
      "     |  __mul__(self, x)\n",
      "     |  \n",
      "     |  __neg__(self)\n",
      "     |  \n",
      "     |  __pow__(self, p)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rmatmul__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(self, x)\n",
      "     |  \n",
      "     |  __sub__(self, x)\n",
      "     |  \n",
      "     |  adjoint(self)\n",
      "     |      Hermitian adjoint.\n",
      "     |      \n",
      "     |      Returns the Hermitian adjoint of self, aka the Hermitian\n",
      "     |      conjugate or Hermitian transpose. For a complex matrix, the\n",
      "     |      Hermitian adjoint is equal to the conjugate transpose.\n",
      "     |      \n",
      "     |      Can be abbreviated self.H instead of self.adjoint().\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A_H : LinearOperator\n",
      "     |          Hermitian adjoint of self.\n",
      "     |  \n",
      "     |  dot(self, x)\n",
      "     |      Matrix-matrix or matrix-vector multiplication.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          1-d or 2-d array, representing a vector or matrix.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Ax : array\n",
      "     |          1-d or 2-d array (depending on the shape of x) that represents\n",
      "     |          the result of applying this linear operator on x.\n",
      "     |  \n",
      "     |  matmat(self, X)\n",
      "     |      Matrix-matrix multiplication.\n",
      "     |      \n",
      "     |      Performs the operation y=A*X where A is an MxN linear\n",
      "     |      operator and X dense N*K matrix or ndarray.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {matrix, ndarray}\n",
      "     |          An array with shape (N,K).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Y : {matrix, ndarray}\n",
      "     |          A matrix or ndarray with shape (M,K) depending on\n",
      "     |          the type of the X argument.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This matmat wraps any user-specified matmat routine or overridden\n",
      "     |      _matmat method to ensure that y has the correct type.\n",
      "     |  \n",
      "     |  matvec(self, x)\n",
      "     |      Matrix-vector multiplication.\n",
      "     |      \n",
      "     |      Performs the operation y=A*x where A is an MxN linear\n",
      "     |      operator and x is a column vector or 1-d array.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : {matrix, ndarray}\n",
      "     |          An array with shape (N,) or (N,1).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : {matrix, ndarray}\n",
      "     |          A matrix or ndarray with shape (M,) or (M,1) depending\n",
      "     |          on the type and shape of the x argument.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This matvec wraps the user-specified matvec routine or overridden\n",
      "     |      _matvec method to ensure that y has the correct shape and type.\n",
      "     |  \n",
      "     |  rmatmat(self, X)\n",
      "     |      Adjoint matrix-matrix multiplication.\n",
      "     |      \n",
      "     |      Performs the operation y = A^H * x where A is an MxN linear\n",
      "     |      operator and x is a column vector or 1-d array, or 2-d array.\n",
      "     |      The default implementation defers to the adjoint.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {matrix, ndarray}\n",
      "     |          A matrix or 2D array.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Y : {matrix, ndarray}\n",
      "     |          A matrix or 2D array depending on the type of the input.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This rmatmat wraps the user-specified rmatmat routine.\n",
      "     |  \n",
      "     |  rmatvec(self, x)\n",
      "     |      Adjoint matrix-vector multiplication.\n",
      "     |      \n",
      "     |      Performs the operation y = A^H * x where A is an MxN linear\n",
      "     |      operator and x is a column vector or 1-d array.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : {matrix, ndarray}\n",
      "     |          An array with shape (M,) or (M,1).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : {matrix, ndarray}\n",
      "     |          A matrix or ndarray with shape (N,) or (N,1) depending\n",
      "     |          on the type and shape of the x argument.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This rmatvec wraps the user-specified rmatvec routine or overridden\n",
      "     |      _rmatvec method to ensure that y has the correct shape and type.\n",
      "     |  \n",
      "     |  transpose(self)\n",
      "     |      Transpose this linear operator.\n",
      "     |      \n",
      "     |      Returns a LinearOperator that represents the transpose of this one.\n",
      "     |      Can be abbreviated self.T instead of self.transpose().\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwargs)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  H\n",
      "     |      Hermitian adjoint.\n",
      "     |      \n",
      "     |      Returns the Hermitian adjoint of self, aka the Hermitian\n",
      "     |      conjugate or Hermitian transpose. For a complex matrix, the\n",
      "     |      Hermitian adjoint is equal to the conjugate transpose.\n",
      "     |      \n",
      "     |      Can be abbreviated self.H instead of self.adjoint().\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A_H : LinearOperator\n",
      "     |          Hermitian adjoint of self.\n",
      "     |  \n",
      "     |  T\n",
      "     |      Transpose this linear operator.\n",
      "     |      \n",
      "     |      Returns a LinearOperator that represents the transpose of this one.\n",
      "     |      Can be abbreviated self.T instead of self.transpose().\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  ndim = 2\n",
      "    \n",
      "    class MatrixRankWarning(builtins.UserWarning)\n",
      "     |  Method resolution order:\n",
      "     |      MatrixRankWarning\n",
      "     |      builtins.UserWarning\n",
      "     |      builtins.Warning\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.UserWarning:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.UserWarning:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class SuperLU(object)\n",
      "     |  LU factorization of a sparse matrix.\n",
      "     |  \n",
      "     |  Factorization is represented as::\n",
      "     |  \n",
      "     |      Pr @ A @ Pc = L @ U\n",
      "     |  \n",
      "     |  To construct these `SuperLU` objects, call the `splu` and `spilu`\n",
      "     |  functions.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  shape\n",
      "     |  nnz\n",
      "     |  perm_c\n",
      "     |  perm_r\n",
      "     |  L\n",
      "     |  U\n",
      "     |  \n",
      "     |  Methods\n",
      "     |  -------\n",
      "     |  solve\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  \n",
      "     |  .. versionadded:: 0.14.0\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  The LU decomposition can be used to solve matrix equations. Consider:\n",
      "     |  \n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from scipy.sparse import csc_matrix, linalg as sla\n",
      "     |  >>> A = csc_matrix([[1,2,0,4],[1,0,0,1],[1,0,2,1],[2,2,1,0.]])\n",
      "     |  \n",
      "     |  This can be solved for a given right-hand side:\n",
      "     |  \n",
      "     |  >>> lu = sla.splu(A)\n",
      "     |  >>> b = np.array([1, 2, 3, 4])\n",
      "     |  >>> x = lu.solve(b)\n",
      "     |  >>> A.dot(x)\n",
      "     |  array([ 1.,  2.,  3.,  4.])\n",
      "     |  \n",
      "     |  The ``lu`` object also contains an explicit representation of the\n",
      "     |  decomposition. The permutations are represented as mappings of\n",
      "     |  indices:\n",
      "     |  \n",
      "     |  >>> lu.perm_r\n",
      "     |  array([0, 2, 1, 3], dtype=int32)\n",
      "     |  >>> lu.perm_c\n",
      "     |  array([2, 0, 1, 3], dtype=int32)\n",
      "     |  \n",
      "     |  The L and U factors are sparse matrices in CSC format:\n",
      "     |  \n",
      "     |  >>> lu.L.A\n",
      "     |  array([[ 1. ,  0. ,  0. ,  0. ],\n",
      "     |         [ 0. ,  1. ,  0. ,  0. ],\n",
      "     |         [ 0. ,  0. ,  1. ,  0. ],\n",
      "     |         [ 1. ,  0.5,  0.5,  1. ]])\n",
      "     |  >>> lu.U.A\n",
      "     |  array([[ 2.,  0.,  1.,  4.],\n",
      "     |         [ 0.,  2.,  1.,  1.],\n",
      "     |         [ 0.,  0.,  1.,  1.],\n",
      "     |         [ 0.,  0.,  0., -5.]])\n",
      "     |  \n",
      "     |  The permutation matrices can be constructed:\n",
      "     |  \n",
      "     |  >>> Pr = csc_matrix((np.ones(4), (lu.perm_r, np.arange(4))))\n",
      "     |  >>> Pc = csc_matrix((np.ones(4), (np.arange(4), lu.perm_c)))\n",
      "     |  \n",
      "     |  We can reassemble the original matrix:\n",
      "     |  \n",
      "     |  >>> (Pr.T @ (lu.L @ lu.U) @ Pc.T).A\n",
      "     |  array([[ 1.,  2.,  0.,  4.],\n",
      "     |         [ 1.,  0.,  0.,  1.],\n",
      "     |         [ 1.,  0.,  2.,  1.],\n",
      "     |         [ 2.,  2.,  1.,  0.]])\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(rhs[, trans])\n",
      "     |      \n",
      "     |      Solves linear system of equations with one or several right-hand sides.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      rhs : ndarray, shape (n,) or (n, k)\n",
      "     |          Right hand side(s) of equation\n",
      "     |      trans : {'N', 'T', 'H'}, optional\n",
      "     |          Type of system to solve::\n",
      "     |      \n",
      "     |              'N':   A   @ x == rhs  (default)\n",
      "     |              'T':   A^T @ x == rhs\n",
      "     |              'H':   A^H @ x == rhs\n",
      "     |      \n",
      "     |          i.e., normal, transposed, and hermitian conjugate.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      x : ndarray, shape ``rhs.shape``\n",
      "     |          Solution vector(s)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  L\n",
      "     |      Lower triangular factor with unit diagonal as a\n",
      "     |      `scipy.sparse.csc_matrix`.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.14.0\n",
      "     |  \n",
      "     |  U\n",
      "     |      Upper triangular factor as a `scipy.sparse.csc_matrix`.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.14.0\n",
      "     |  \n",
      "     |  nnz\n",
      "     |      Number of nonzero elements in the matrix.\n",
      "     |  \n",
      "     |  perm_c\n",
      "     |      Permutation Pc represented as an array of indices.\n",
      "     |      \n",
      "     |      The column permutation matrix can be reconstructed via:\n",
      "     |      \n",
      "     |      >>> Pc = np.zeros((n, n))\n",
      "     |      >>> Pc[np.arange(n), perm_c] = 1\n",
      "     |  \n",
      "     |  perm_r\n",
      "     |      Permutation Pr represented as an array of indices.\n",
      "     |      \n",
      "     |      The row permutation matrix can be reconstructed via:\n",
      "     |      \n",
      "     |      >>> Pr = np.zeros((n, n))\n",
      "     |      >>> Pr[perm_r, np.arange(n)] = 1\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Shape of the original matrix as a tuple of ints.\n",
      "\n",
      "FUNCTIONS\n",
      "    aslinearoperator(A)\n",
      "        Return A as a LinearOperator.\n",
      "        \n",
      "        'A' may be any of the following types:\n",
      "         - ndarray\n",
      "         - matrix\n",
      "         - sparse matrix (e.g. csr_matrix, lil_matrix, etc.)\n",
      "         - LinearOperator\n",
      "         - An object with .shape and .matvec attributes\n",
      "        \n",
      "        See the LinearOperator documentation for additional information.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        If 'A' has no .dtype attribute, the data type is determined by calling\n",
      "        :func:`LinearOperator.matvec()` - set the .dtype attribute to prevent this\n",
      "        call upon the linear operator creation.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse.linalg import aslinearoperator\n",
      "        >>> M = np.array([[1,2,3],[4,5,6]], dtype=np.int32)\n",
      "        >>> aslinearoperator(M)\n",
      "        <2x3 MatrixLinearOperator with dtype=int32>\n",
      "    \n",
      "    bicg(A, b, x0=None, tol=1e-05, maxiter=None, M=None, callback=None, atol=None)\n",
      "        Use BIConjugate Gradient iteration to solve ``Ax = b``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, ndarray, LinearOperator}\n",
      "            The real or complex N-by-N matrix of the linear system.\n",
      "            Alternatively, ``A`` can be a linear operator which can\n",
      "            produce ``Ax`` and ``A^T x`` using, e.g.,\n",
      "            ``scipy.sparse.linalg.LinearOperator``.\n",
      "        b : ndarray\n",
      "            Right hand side of the linear system. Has shape (N,) or (N,1).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : ndarray\n",
      "            The converged solution.\n",
      "        info : integer\n",
      "            Provides convergence information:\n",
      "                0  : successful exit\n",
      "                >0 : convergence to tolerance not achieved, number of iterations\n",
      "                <0 : illegal input or breakdown\n",
      "        \n",
      "        Other Parameters\n",
      "        ----------------\n",
      "        x0 : ndarray\n",
      "            Starting guess for the solution.\n",
      "        tol, atol : float, optional\n",
      "            Tolerances for convergence, ``norm(residual) <= max(tol*norm(b), atol)``.\n",
      "            The default for ``atol`` is ``'legacy'``, which emulates\n",
      "            a different legacy behavior.\n",
      "        \n",
      "            .. warning::\n",
      "        \n",
      "               The default value for `atol` will be changed in a future release.\n",
      "               For future compatibility, specify `atol` explicitly.\n",
      "        maxiter : integer\n",
      "            Maximum number of iterations.  Iteration will stop after maxiter\n",
      "            steps even if the specified tolerance has not been achieved.\n",
      "        M : {sparse matrix, ndarray, LinearOperator}\n",
      "            Preconditioner for A.  The preconditioner should approximate the\n",
      "            inverse of A.  Effective preconditioning dramatically improves the\n",
      "            rate of convergence, which implies that fewer iterations are needed\n",
      "            to reach a given error tolerance.\n",
      "        callback : function\n",
      "            User-supplied function to call after each iteration.  It is called\n",
      "            as callback(xk), where xk is the current solution vector.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import bicg\n",
      "        >>> A = csc_matrix([[3, 2, 0], [1, -1, 0], [0, 5, 1]], dtype=float)\n",
      "        >>> b = np.array([2, 4, -1], dtype=float)\n",
      "        >>> x, exitCode = bicg(A, b)\n",
      "        >>> print(exitCode)            # 0 indicates successful convergence\n",
      "        0\n",
      "        >>> np.allclose(A.dot(x), b)\n",
      "        True\n",
      "    \n",
      "    bicgstab(A, b, x0=None, tol=1e-05, maxiter=None, M=None, callback=None, atol=None)\n",
      "        Use BIConjugate Gradient STABilized iteration to solve ``Ax = b``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, ndarray, LinearOperator}\n",
      "            The real or complex N-by-N matrix of the linear system.\n",
      "            Alternatively, ``A`` can be a linear operator which can\n",
      "            produce ``Ax`` using, e.g.,\n",
      "            ``scipy.sparse.linalg.LinearOperator``.\n",
      "        b : ndarray\n",
      "            Right hand side of the linear system. Has shape (N,) or (N,1).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : ndarray\n",
      "            The converged solution.\n",
      "        info : integer\n",
      "            Provides convergence information:\n",
      "                0  : successful exit\n",
      "                >0 : convergence to tolerance not achieved, number of iterations\n",
      "                <0 : illegal input or breakdown\n",
      "        \n",
      "        Other Parameters\n",
      "        ----------------\n",
      "        x0 : ndarray\n",
      "            Starting guess for the solution.\n",
      "        tol, atol : float, optional\n",
      "            Tolerances for convergence, ``norm(residual) <= max(tol*norm(b), atol)``.\n",
      "            The default for ``atol`` is ``'legacy'``, which emulates\n",
      "            a different legacy behavior.\n",
      "        \n",
      "            .. warning::\n",
      "        \n",
      "               The default value for `atol` will be changed in a future release.\n",
      "               For future compatibility, specify `atol` explicitly.\n",
      "        maxiter : integer\n",
      "            Maximum number of iterations.  Iteration will stop after maxiter\n",
      "            steps even if the specified tolerance has not been achieved.\n",
      "        M : {sparse matrix, ndarray, LinearOperator}\n",
      "            Preconditioner for A.  The preconditioner should approximate the\n",
      "            inverse of A.  Effective preconditioning dramatically improves the\n",
      "            rate of convergence, which implies that fewer iterations are needed\n",
      "            to reach a given error tolerance.\n",
      "        callback : function\n",
      "            User-supplied function to call after each iteration.  It is called\n",
      "            as callback(xk), where xk is the current solution vector.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import bicgstab\n",
      "        >>> R = np.array([[4, 2, 0, 1],\n",
      "        ...               [3, 0, 0, 2],\n",
      "        ...               [0, 1, 1, 1],\n",
      "        ...               [0, 2, 1, 0]])\n",
      "        >>> A = csc_matrix(R)\n",
      "        >>> b = np.array([-1, -0.5, -1, 2])\n",
      "        >>> x, exit_code = bicgstab(A, b)\n",
      "        >>> print(exit_code)  # 0 indicates successful convergence\n",
      "        0\n",
      "        >>> np.allclose(A.dot(x), b)\n",
      "        True\n",
      "    \n",
      "    cg(A, b, x0=None, tol=1e-05, maxiter=None, M=None, callback=None, atol=None)\n",
      "        Use Conjugate Gradient iteration to solve ``Ax = b``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, ndarray, LinearOperator}\n",
      "            The real or complex N-by-N matrix of the linear system.\n",
      "            ``A`` must represent a hermitian, positive definite matrix.\n",
      "            Alternatively, ``A`` can be a linear operator which can\n",
      "            produce ``Ax`` using, e.g.,\n",
      "            ``scipy.sparse.linalg.LinearOperator``.\n",
      "        b : ndarray\n",
      "            Right hand side of the linear system. Has shape (N,) or (N,1).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : ndarray\n",
      "            The converged solution.\n",
      "        info : integer\n",
      "            Provides convergence information:\n",
      "                0  : successful exit\n",
      "                >0 : convergence to tolerance not achieved, number of iterations\n",
      "                <0 : illegal input or breakdown\n",
      "        \n",
      "        Other Parameters\n",
      "        ----------------\n",
      "        x0 : ndarray\n",
      "            Starting guess for the solution.\n",
      "        tol, atol : float, optional\n",
      "            Tolerances for convergence, ``norm(residual) <= max(tol*norm(b), atol)``.\n",
      "            The default for ``atol`` is ``'legacy'``, which emulates\n",
      "            a different legacy behavior.\n",
      "        \n",
      "            .. warning::\n",
      "        \n",
      "               The default value for `atol` will be changed in a future release.\n",
      "               For future compatibility, specify `atol` explicitly.\n",
      "        maxiter : integer\n",
      "            Maximum number of iterations.  Iteration will stop after maxiter\n",
      "            steps even if the specified tolerance has not been achieved.\n",
      "        M : {sparse matrix, ndarray, LinearOperator}\n",
      "            Preconditioner for A.  The preconditioner should approximate the\n",
      "            inverse of A.  Effective preconditioning dramatically improves the\n",
      "            rate of convergence, which implies that fewer iterations are needed\n",
      "            to reach a given error tolerance.\n",
      "        callback : function\n",
      "            User-supplied function to call after each iteration.  It is called\n",
      "            as callback(xk), where xk is the current solution vector.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import cg\n",
      "        >>> P = np.array([[4, 0, 1, 0],\n",
      "        ...               [0, 5, 0, 0],\n",
      "        ...               [1, 0, 3, 2],\n",
      "        ...               [0, 0, 2, 4]])\n",
      "        >>> A = csc_matrix(P)\n",
      "        >>> b = np.array([-1, -0.5, -1, 2])\n",
      "        >>> x, exit_code = cg(A, b)\n",
      "        >>> print(exit_code)    # 0 indicates successful convergence\n",
      "        0\n",
      "        >>> np.allclose(A.dot(x), b)\n",
      "        True\n",
      "    \n",
      "    cgs(A, b, x0=None, tol=1e-05, maxiter=None, M=None, callback=None, atol=None)\n",
      "        Use Conjugate Gradient Squared iteration to solve ``Ax = b``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, ndarray, LinearOperator}\n",
      "            The real-valued N-by-N matrix of the linear system.\n",
      "            Alternatively, ``A`` can be a linear operator which can\n",
      "            produce ``Ax`` using, e.g.,\n",
      "            ``scipy.sparse.linalg.LinearOperator``.\n",
      "        b : ndarray\n",
      "            Right hand side of the linear system. Has shape (N,) or (N,1).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : ndarray\n",
      "            The converged solution.\n",
      "        info : integer\n",
      "            Provides convergence information:\n",
      "                0  : successful exit\n",
      "                >0 : convergence to tolerance not achieved, number of iterations\n",
      "                <0 : illegal input or breakdown\n",
      "        \n",
      "        Other Parameters\n",
      "        ----------------\n",
      "        x0 : ndarray\n",
      "            Starting guess for the solution.\n",
      "        tol, atol : float, optional\n",
      "            Tolerances for convergence, ``norm(residual) <= max(tol*norm(b), atol)``.\n",
      "            The default for ``atol`` is ``'legacy'``, which emulates\n",
      "            a different legacy behavior.\n",
      "        \n",
      "            .. warning::\n",
      "        \n",
      "               The default value for `atol` will be changed in a future release.\n",
      "               For future compatibility, specify `atol` explicitly.\n",
      "        maxiter : integer\n",
      "            Maximum number of iterations.  Iteration will stop after maxiter\n",
      "            steps even if the specified tolerance has not been achieved.\n",
      "        M : {sparse matrix, ndarray, LinearOperator}\n",
      "            Preconditioner for A.  The preconditioner should approximate the\n",
      "            inverse of A.  Effective preconditioning dramatically improves the\n",
      "            rate of convergence, which implies that fewer iterations are needed\n",
      "            to reach a given error tolerance.\n",
      "        callback : function\n",
      "            User-supplied function to call after each iteration.  It is called\n",
      "            as callback(xk), where xk is the current solution vector.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import cgs\n",
      "        >>> R = np.array([[4, 2, 0, 1],\n",
      "        ...               [3, 0, 0, 2],\n",
      "        ...               [0, 1, 1, 1],\n",
      "        ...               [0, 2, 1, 0]])\n",
      "        >>> A = csc_matrix(R)\n",
      "        >>> b = np.array([-1, -0.5, -1, 2])\n",
      "        >>> x, exit_code = cgs(A, b)\n",
      "        >>> print(exit_code)  # 0 indicates successful convergence\n",
      "        0\n",
      "        >>> np.allclose(A.dot(x), b)\n",
      "        True\n",
      "    \n",
      "    eigs(A, k=6, M=None, sigma=None, which='LM', v0=None, ncv=None, maxiter=None, tol=0, return_eigenvectors=True, Minv=None, OPinv=None, OPpart=None)\n",
      "        Find k eigenvalues and eigenvectors of the square matrix A.\n",
      "        \n",
      "        Solves ``A @ x[i] = w[i] * x[i]``, the standard eigenvalue problem\n",
      "        for w[i] eigenvalues with corresponding eigenvectors x[i].\n",
      "        \n",
      "        If M is specified, solves ``A @ x[i] = w[i] * M @ x[i]``, the\n",
      "        generalized eigenvalue problem for w[i] eigenvalues\n",
      "        with corresponding eigenvectors x[i]\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : ndarray, sparse matrix or LinearOperator\n",
      "            An array, sparse matrix, or LinearOperator representing\n",
      "            the operation ``A @ x``, where A is a real or complex square matrix.\n",
      "        k : int, optional\n",
      "            The number of eigenvalues and eigenvectors desired.\n",
      "            `k` must be smaller than N-1. It is not possible to compute all\n",
      "            eigenvectors of a matrix.\n",
      "        M : ndarray, sparse matrix or LinearOperator, optional\n",
      "            An array, sparse matrix, or LinearOperator representing\n",
      "            the operation M@x for the generalized eigenvalue problem\n",
      "        \n",
      "                A @ x = w * M @ x.\n",
      "        \n",
      "            M must represent a real symmetric matrix if A is real, and must\n",
      "            represent a complex Hermitian matrix if A is complex. For best\n",
      "            results, the data type of M should be the same as that of A.\n",
      "            Additionally:\n",
      "        \n",
      "                If `sigma` is None, M is positive definite\n",
      "        \n",
      "                If sigma is specified, M is positive semi-definite\n",
      "        \n",
      "            If sigma is None, eigs requires an operator to compute the solution\n",
      "            of the linear equation ``M @ x = b``.  This is done internally via a\n",
      "            (sparse) LU decomposition for an explicit matrix M, or via an\n",
      "            iterative solver for a general linear operator.  Alternatively,\n",
      "            the user can supply the matrix or operator Minv, which gives\n",
      "            ``x = Minv @ b = M^-1 @ b``.\n",
      "        sigma : real or complex, optional\n",
      "            Find eigenvalues near sigma using shift-invert mode.  This requires\n",
      "            an operator to compute the solution of the linear system\n",
      "            ``[A - sigma * M] @ x = b``, where M is the identity matrix if\n",
      "            unspecified. This is computed internally via a (sparse) LU\n",
      "            decomposition for explicit matrices A & M, or via an iterative\n",
      "            solver if either A or M is a general linear operator.\n",
      "            Alternatively, the user can supply the matrix or operator OPinv,\n",
      "            which gives ``x = OPinv @ b = [A - sigma * M]^-1 @ b``.\n",
      "            For a real matrix A, shift-invert can either be done in imaginary\n",
      "            mode or real mode, specified by the parameter OPpart ('r' or 'i').\n",
      "            Note that when sigma is specified, the keyword 'which' (below)\n",
      "            refers to the shifted eigenvalues ``w'[i]`` where:\n",
      "        \n",
      "                If A is real and OPpart == 'r' (default),\n",
      "                  ``w'[i] = 1/2 * [1/(w[i]-sigma) + 1/(w[i]-conj(sigma))]``.\n",
      "        \n",
      "                If A is real and OPpart == 'i',\n",
      "                  ``w'[i] = 1/2i * [1/(w[i]-sigma) - 1/(w[i]-conj(sigma))]``.\n",
      "        \n",
      "                If A is complex, ``w'[i] = 1/(w[i]-sigma)``.\n",
      "        \n",
      "        v0 : ndarray, optional\n",
      "            Starting vector for iteration.\n",
      "            Default: random\n",
      "        ncv : int, optional\n",
      "            The number of Lanczos vectors generated\n",
      "            `ncv` must be greater than `k`; it is recommended that ``ncv > 2*k``.\n",
      "            Default: ``min(n, max(2*k + 1, 20))``\n",
      "        which : str, ['LM' | 'SM' | 'LR' | 'SR' | 'LI' | 'SI'], optional\n",
      "            Which `k` eigenvectors and eigenvalues to find:\n",
      "        \n",
      "                'LM' : largest magnitude\n",
      "        \n",
      "                'SM' : smallest magnitude\n",
      "        \n",
      "                'LR' : largest real part\n",
      "        \n",
      "                'SR' : smallest real part\n",
      "        \n",
      "                'LI' : largest imaginary part\n",
      "        \n",
      "                'SI' : smallest imaginary part\n",
      "        \n",
      "            When sigma != None, 'which' refers to the shifted eigenvalues w'[i]\n",
      "            (see discussion in 'sigma', above).  ARPACK is generally better\n",
      "            at finding large values than small values.  If small eigenvalues are\n",
      "            desired, consider using shift-invert mode for better performance.\n",
      "        maxiter : int, optional\n",
      "            Maximum number of Arnoldi update iterations allowed\n",
      "            Default: ``n*10``\n",
      "        tol : float, optional\n",
      "            Relative accuracy for eigenvalues (stopping criterion)\n",
      "            The default value of 0 implies machine precision.\n",
      "        return_eigenvectors : bool, optional\n",
      "            Return eigenvectors (True) in addition to eigenvalues\n",
      "        Minv : ndarray, sparse matrix or LinearOperator, optional\n",
      "            See notes in M, above.\n",
      "        OPinv : ndarray, sparse matrix or LinearOperator, optional\n",
      "            See notes in sigma, above.\n",
      "        OPpart : {'r' or 'i'}, optional\n",
      "            See notes in sigma, above\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        w : ndarray\n",
      "            Array of k eigenvalues.\n",
      "        v : ndarray\n",
      "            An array of `k` eigenvectors.\n",
      "            ``v[:, i]`` is the eigenvector corresponding to the eigenvalue w[i].\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        ArpackNoConvergence\n",
      "            When the requested convergence is not obtained.\n",
      "            The currently converged eigenvalues and eigenvectors can be found\n",
      "            as ``eigenvalues`` and ``eigenvectors`` attributes of the exception\n",
      "            object.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        eigsh : eigenvalues and eigenvectors for symmetric matrix A\n",
      "        svds : singular value decomposition for a matrix A\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This function is a wrapper to the ARPACK [1]_ SNEUPD, DNEUPD, CNEUPD,\n",
      "        ZNEUPD, functions which use the Implicitly Restarted Arnoldi Method to\n",
      "        find the eigenvalues and eigenvectors [2]_.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] ARPACK Software, http://www.caam.rice.edu/software/ARPACK/\n",
      "        .. [2] R. B. Lehoucq, D. C. Sorensen, and C. Yang,  ARPACK USERS GUIDE:\n",
      "           Solution of Large Scale Eigenvalue Problems by Implicitly Restarted\n",
      "           Arnoldi Methods. SIAM, Philadelphia, PA, 1998.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Find 6 eigenvectors of the identity matrix:\n",
      "        \n",
      "        >>> from scipy.sparse.linalg import eigs\n",
      "        >>> id = np.eye(13)\n",
      "        >>> vals, vecs = eigs(id, k=6)\n",
      "        >>> vals\n",
      "        array([ 1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j])\n",
      "        >>> vecs.shape\n",
      "        (13, 6)\n",
      "    \n",
      "    eigsh(A, k=6, M=None, sigma=None, which='LM', v0=None, ncv=None, maxiter=None, tol=0, return_eigenvectors=True, Minv=None, OPinv=None, mode='normal')\n",
      "        Find k eigenvalues and eigenvectors of the real symmetric square matrix\n",
      "        or complex Hermitian matrix A.\n",
      "        \n",
      "        Solves ``A @ x[i] = w[i] * x[i]``, the standard eigenvalue problem for\n",
      "        w[i] eigenvalues with corresponding eigenvectors x[i].\n",
      "        \n",
      "        If M is specified, solves ``A @ x[i] = w[i] * M @ x[i]``, the\n",
      "        generalized eigenvalue problem for w[i] eigenvalues\n",
      "        with corresponding eigenvectors x[i].\n",
      "        \n",
      "        Note that there is no specialized routine for the case when A is a complex\n",
      "        Hermitian matrix. In this case, ``eigsh()`` will call ``eigs()`` and return the\n",
      "        real parts of the eigenvalues thus obtained.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : ndarray, sparse matrix or LinearOperator\n",
      "            A square operator representing the operation ``A @ x``, where ``A`` is\n",
      "            real symmetric or complex Hermitian. For buckling mode (see below)\n",
      "            ``A`` must additionally be positive-definite.\n",
      "        k : int, optional\n",
      "            The number of eigenvalues and eigenvectors desired.\n",
      "            `k` must be smaller than N. It is not possible to compute all\n",
      "            eigenvectors of a matrix.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        w : array\n",
      "            Array of k eigenvalues.\n",
      "        v : array\n",
      "            An array representing the `k` eigenvectors.  The column ``v[:, i]`` is\n",
      "            the eigenvector corresponding to the eigenvalue ``w[i]``.\n",
      "        \n",
      "        Other Parameters\n",
      "        ----------------\n",
      "        M : An N x N matrix, array, sparse matrix, or linear operator representing\n",
      "            the operation ``M @ x`` for the generalized eigenvalue problem\n",
      "        \n",
      "                A @ x = w * M @ x.\n",
      "        \n",
      "            M must represent a real symmetric matrix if A is real, and must\n",
      "            represent a complex Hermitian matrix if A is complex. For best\n",
      "            results, the data type of M should be the same as that of A.\n",
      "            Additionally:\n",
      "        \n",
      "                If sigma is None, M is symmetric positive definite.\n",
      "        \n",
      "                If sigma is specified, M is symmetric positive semi-definite.\n",
      "        \n",
      "                In buckling mode, M is symmetric indefinite.\n",
      "        \n",
      "            If sigma is None, eigsh requires an operator to compute the solution\n",
      "            of the linear equation ``M @ x = b``. This is done internally via a\n",
      "            (sparse) LU decomposition for an explicit matrix M, or via an\n",
      "            iterative solver for a general linear operator.  Alternatively,\n",
      "            the user can supply the matrix or operator Minv, which gives\n",
      "            ``x = Minv @ b = M^-1 @ b``.\n",
      "        sigma : real\n",
      "            Find eigenvalues near sigma using shift-invert mode.  This requires\n",
      "            an operator to compute the solution of the linear system\n",
      "            ``[A - sigma * M] x = b``, where M is the identity matrix if\n",
      "            unspecified.  This is computed internally via a (sparse) LU\n",
      "            decomposition for explicit matrices A & M, or via an iterative\n",
      "            solver if either A or M is a general linear operator.\n",
      "            Alternatively, the user can supply the matrix or operator OPinv,\n",
      "            which gives ``x = OPinv @ b = [A - sigma * M]^-1 @ b``.\n",
      "            Note that when sigma is specified, the keyword 'which' refers to\n",
      "            the shifted eigenvalues ``w'[i]`` where:\n",
      "        \n",
      "                if mode == 'normal', ``w'[i] = 1 / (w[i] - sigma)``.\n",
      "        \n",
      "                if mode == 'cayley', ``w'[i] = (w[i] + sigma) / (w[i] - sigma)``.\n",
      "        \n",
      "                if mode == 'buckling', ``w'[i] = w[i] / (w[i] - sigma)``.\n",
      "        \n",
      "            (see further discussion in 'mode' below)\n",
      "        v0 : ndarray, optional\n",
      "            Starting vector for iteration.\n",
      "            Default: random\n",
      "        ncv : int, optional\n",
      "            The number of Lanczos vectors generated ncv must be greater than k and\n",
      "            smaller than n; it is recommended that ``ncv > 2*k``.\n",
      "            Default: ``min(n, max(2*k + 1, 20))``\n",
      "        which : str ['LM' | 'SM' | 'LA' | 'SA' | 'BE']\n",
      "            If A is a complex Hermitian matrix, 'BE' is invalid.\n",
      "            Which `k` eigenvectors and eigenvalues to find:\n",
      "        \n",
      "                'LM' : Largest (in magnitude) eigenvalues.\n",
      "        \n",
      "                'SM' : Smallest (in magnitude) eigenvalues.\n",
      "        \n",
      "                'LA' : Largest (algebraic) eigenvalues.\n",
      "        \n",
      "                'SA' : Smallest (algebraic) eigenvalues.\n",
      "        \n",
      "                'BE' : Half (k/2) from each end of the spectrum.\n",
      "        \n",
      "            When k is odd, return one more (k/2+1) from the high end.\n",
      "            When sigma != None, 'which' refers to the shifted eigenvalues ``w'[i]``\n",
      "            (see discussion in 'sigma', above).  ARPACK is generally better\n",
      "            at finding large values than small values.  If small eigenvalues are\n",
      "            desired, consider using shift-invert mode for better performance.\n",
      "        maxiter : int, optional\n",
      "            Maximum number of Arnoldi update iterations allowed.\n",
      "            Default: ``n*10``\n",
      "        tol : float\n",
      "            Relative accuracy for eigenvalues (stopping criterion).\n",
      "            The default value of 0 implies machine precision.\n",
      "        Minv : N x N matrix, array, sparse matrix, or LinearOperator\n",
      "            See notes in M, above.\n",
      "        OPinv : N x N matrix, array, sparse matrix, or LinearOperator\n",
      "            See notes in sigma, above.\n",
      "        return_eigenvectors : bool\n",
      "            Return eigenvectors (True) in addition to eigenvalues.\n",
      "            This value determines the order in which eigenvalues are sorted.\n",
      "            The sort order is also dependent on the `which` variable.\n",
      "        \n",
      "                For which = 'LM' or 'SA':\n",
      "                    If `return_eigenvectors` is True, eigenvalues are sorted by\n",
      "                    algebraic value.\n",
      "        \n",
      "                    If `return_eigenvectors` is False, eigenvalues are sorted by\n",
      "                    absolute value.\n",
      "        \n",
      "                For which = 'BE' or 'LA':\n",
      "                    eigenvalues are always sorted by algebraic value.\n",
      "        \n",
      "                For which = 'SM':\n",
      "                    If `return_eigenvectors` is True, eigenvalues are sorted by\n",
      "                    algebraic value.\n",
      "        \n",
      "                    If `return_eigenvectors` is False, eigenvalues are sorted by\n",
      "                    decreasing absolute value.\n",
      "        \n",
      "        mode : string ['normal' | 'buckling' | 'cayley']\n",
      "            Specify strategy to use for shift-invert mode.  This argument applies\n",
      "            only for real-valued A and sigma != None.  For shift-invert mode,\n",
      "            ARPACK internally solves the eigenvalue problem\n",
      "            ``OP @ x'[i] = w'[i] * B @ x'[i]``\n",
      "            and transforms the resulting Ritz vectors x'[i] and Ritz values w'[i]\n",
      "            into the desired eigenvectors and eigenvalues of the problem\n",
      "            ``A @ x[i] = w[i] * M @ x[i]``.\n",
      "            The modes are as follows:\n",
      "        \n",
      "                'normal' :\n",
      "                    OP = [A - sigma * M]^-1 @ M,\n",
      "                    B = M,\n",
      "                    w'[i] = 1 / (w[i] - sigma)\n",
      "        \n",
      "                'buckling' :\n",
      "                    OP = [A - sigma * M]^-1 @ A,\n",
      "                    B = A,\n",
      "                    w'[i] = w[i] / (w[i] - sigma)\n",
      "        \n",
      "                'cayley' :\n",
      "                    OP = [A - sigma * M]^-1 @ [A + sigma * M],\n",
      "                    B = M,\n",
      "                    w'[i] = (w[i] + sigma) / (w[i] - sigma)\n",
      "        \n",
      "            The choice of mode will affect which eigenvalues are selected by\n",
      "            the keyword 'which', and can also impact the stability of\n",
      "            convergence (see [2] for a discussion).\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        ArpackNoConvergence\n",
      "            When the requested convergence is not obtained.\n",
      "        \n",
      "            The currently converged eigenvalues and eigenvectors can be found\n",
      "            as ``eigenvalues`` and ``eigenvectors`` attributes of the exception\n",
      "            object.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        eigs : eigenvalues and eigenvectors for a general (nonsymmetric) matrix A\n",
      "        svds : singular value decomposition for a matrix A\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This function is a wrapper to the ARPACK [1]_ SSEUPD and DSEUPD\n",
      "        functions which use the Implicitly Restarted Lanczos Method to\n",
      "        find the eigenvalues and eigenvectors [2]_.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] ARPACK Software, http://www.caam.rice.edu/software/ARPACK/\n",
      "        .. [2] R. B. Lehoucq, D. C. Sorensen, and C. Yang,  ARPACK USERS GUIDE:\n",
      "           Solution of Large Scale Eigenvalue Problems by Implicitly Restarted\n",
      "           Arnoldi Methods. SIAM, Philadelphia, PA, 1998.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse.linalg import eigsh\n",
      "        >>> identity = np.eye(13)\n",
      "        >>> eigenvalues, eigenvectors = eigsh(identity, k=6)\n",
      "        >>> eigenvalues\n",
      "        array([1., 1., 1., 1., 1., 1.])\n",
      "        >>> eigenvectors.shape\n",
      "        (13, 6)\n",
      "    \n",
      "    expm(A)\n",
      "        Compute the matrix exponential using Pade approximation.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : (M,M) array_like or sparse matrix\n",
      "            2D Array or Matrix (sparse or dense) to be exponentiated\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        expA : (M,M) ndarray\n",
      "            Matrix exponential of `A`\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This is algorithm (6.1) which is a simplification of algorithm (5.1).\n",
      "        \n",
      "        .. versionadded:: 0.12.0\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Awad H. Al-Mohy and Nicholas J. Higham (2009)\n",
      "               \"A New Scaling and Squaring Algorithm for the Matrix Exponential.\"\n",
      "               SIAM Journal on Matrix Analysis and Applications.\n",
      "               31 (3). pp. 970-989. ISSN 1095-7162\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import expm\n",
      "        >>> A = csc_matrix([[1, 0, 0], [0, 2, 0], [0, 0, 3]])\n",
      "        >>> A.toarray()\n",
      "        array([[1, 0, 0],\n",
      "               [0, 2, 0],\n",
      "               [0, 0, 3]], dtype=int64)\n",
      "        >>> Aexp = expm(A)\n",
      "        >>> Aexp\n",
      "        <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "            with 3 stored elements in Compressed Sparse Column format>\n",
      "        >>> Aexp.toarray()\n",
      "        array([[  2.71828183,   0.        ,   0.        ],\n",
      "               [  0.        ,   7.3890561 ,   0.        ],\n",
      "               [  0.        ,   0.        ,  20.08553692]])\n",
      "    \n",
      "    expm_multiply(A, B, start=None, stop=None, num=None, endpoint=None, traceA=None)\n",
      "        Compute the action of the matrix exponential of A on B.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : transposable linear operator\n",
      "            The operator whose exponential is of interest.\n",
      "        B : ndarray\n",
      "            The matrix or vector to be multiplied by the matrix exponential of A.\n",
      "        start : scalar, optional\n",
      "            The starting time point of the sequence.\n",
      "        stop : scalar, optional\n",
      "            The end time point of the sequence, unless `endpoint` is set to False.\n",
      "            In that case, the sequence consists of all but the last of ``num + 1``\n",
      "            evenly spaced time points, so that `stop` is excluded.\n",
      "            Note that the step size changes when `endpoint` is False.\n",
      "        num : int, optional\n",
      "            Number of time points to use.\n",
      "        endpoint : bool, optional\n",
      "            If True, `stop` is the last time point.  Otherwise, it is not included.\n",
      "        traceA : scalar, optional\n",
      "            Trace of `A`. If not given the trace is estimated for linear operators,\n",
      "            or calculated exactly for sparse matrices. It is used to precondition\n",
      "            `A`, thus an approximate trace is acceptable.\n",
      "            For linear operators, `traceA` should be provided to ensure performance\n",
      "            as the estimation is not guaranteed to be reliable for all cases.\n",
      "        \n",
      "            .. versionadded: 1.9.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        expm_A_B : ndarray\n",
      "             The result of the action :math:`e^{t_k A} B`.\n",
      "        \n",
      "        Warns\n",
      "        -----\n",
      "        UserWarning\n",
      "            If `A` is a linear operator and ``traceA==None`` (default).\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The optional arguments defining the sequence of evenly spaced time points\n",
      "        are compatible with the arguments of `numpy.linspace`.\n",
      "        \n",
      "        The output ndarray shape is somewhat complicated so I explain it here.\n",
      "        The ndim of the output could be either 1, 2, or 3.\n",
      "        It would be 1 if you are computing the expm action on a single vector\n",
      "        at a single time point.\n",
      "        It would be 2 if you are computing the expm action on a vector\n",
      "        at multiple time points, or if you are computing the expm action\n",
      "        on a matrix at a single time point.\n",
      "        It would be 3 if you want the action on a matrix with multiple\n",
      "        columns at multiple time points.\n",
      "        If multiple time points are requested, expm_A_B[0] will always\n",
      "        be the action of the expm at the first time point,\n",
      "        regardless of whether the action is on a vector or a matrix.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Awad H. Al-Mohy and Nicholas J. Higham (2011)\n",
      "               \"Computing the Action of the Matrix Exponential,\n",
      "               with an Application to Exponential Integrators.\"\n",
      "               SIAM Journal on Scientific Computing,\n",
      "               33 (2). pp. 488-511. ISSN 1064-8275\n",
      "               http://eprints.ma.man.ac.uk/1591/\n",
      "        \n",
      "        .. [2] Nicholas J. Higham and Awad H. Al-Mohy (2010)\n",
      "               \"Computing Matrix Functions.\"\n",
      "               Acta Numerica,\n",
      "               19. 159-208. ISSN 0962-4929\n",
      "               http://eprints.ma.man.ac.uk/1451/\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import expm, expm_multiply\n",
      "        >>> A = csc_matrix([[1, 0], [0, 1]])\n",
      "        >>> A.toarray()\n",
      "        array([[1, 0],\n",
      "               [0, 1]], dtype=int64)\n",
      "        >>> B = np.array([np.exp(-1.), np.exp(-2.)])\n",
      "        >>> B\n",
      "        array([ 0.36787944,  0.13533528])\n",
      "        >>> expm_multiply(A, B, start=1, stop=2, num=3, endpoint=True)\n",
      "        array([[ 1.        ,  0.36787944],\n",
      "               [ 1.64872127,  0.60653066],\n",
      "               [ 2.71828183,  1.        ]])\n",
      "        >>> expm(A).dot(B)                  # Verify 1st timestep\n",
      "        array([ 1.        ,  0.36787944])\n",
      "        >>> expm(1.5*A).dot(B)              # Verify 2nd timestep\n",
      "        array([ 1.64872127,  0.60653066])\n",
      "        >>> expm(2*A).dot(B)                # Verify 3rd timestep\n",
      "        array([ 2.71828183,  1.        ])\n",
      "    \n",
      "    factorized(A)\n",
      "        Return a function for solving a sparse linear system, with A pre-factorized.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : (N, N) array_like\n",
      "            Input. A in CSC format is most efficient. A CSR format matrix will\n",
      "            be converted to CSC before factorization.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        solve : callable\n",
      "            To solve the linear system of equations given in `A`, the `solve`\n",
      "            callable should be passed an ndarray of shape (N,).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse.linalg import factorized\n",
      "        >>> A = np.array([[ 3. ,  2. , -1. ],\n",
      "        ...               [ 2. , -2. ,  4. ],\n",
      "        ...               [-1. ,  0.5, -1. ]])\n",
      "        >>> solve = factorized(A) # Makes LU decomposition.\n",
      "        >>> rhs1 = np.array([1, -2, 0])\n",
      "        >>> solve(rhs1) # Uses the LU factors.\n",
      "        array([ 1., -2., -2.])\n",
      "    \n",
      "    gcrotmk(A, b, x0=None, tol=1e-05, maxiter=1000, M=None, callback=None, m=20, k=None, CU=None, discard_C=False, truncate='oldest', atol=None)\n",
      "        Solve a matrix equation using flexible GCROT(m,k) algorithm.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, ndarray, LinearOperator}\n",
      "            The real or complex N-by-N matrix of the linear system.\n",
      "            Alternatively, ``A`` can be a linear operator which can\n",
      "            produce ``Ax`` using, e.g.,\n",
      "            ``scipy.sparse.linalg.LinearOperator``.\n",
      "        b : ndarray\n",
      "            Right hand side of the linear system. Has shape (N,) or (N,1).\n",
      "        x0 : ndarray\n",
      "            Starting guess for the solution.\n",
      "        tol, atol : float, optional\n",
      "            Tolerances for convergence, ``norm(residual) <= max(tol*norm(b), atol)``.\n",
      "            The default for ``atol`` is `tol`.\n",
      "        \n",
      "            .. warning::\n",
      "        \n",
      "               The default value for `atol` will be changed in a future release.\n",
      "               For future compatibility, specify `atol` explicitly.\n",
      "        maxiter : int, optional\n",
      "            Maximum number of iterations.  Iteration will stop after maxiter\n",
      "            steps even if the specified tolerance has not been achieved.\n",
      "        M : {sparse matrix, ndarray, LinearOperator}, optional\n",
      "            Preconditioner for A.  The preconditioner should approximate the\n",
      "            inverse of A. gcrotmk is a 'flexible' algorithm and the preconditioner\n",
      "            can vary from iteration to iteration. Effective preconditioning\n",
      "            dramatically improves the rate of convergence, which implies that\n",
      "            fewer iterations are needed to reach a given error tolerance.\n",
      "        callback : function, optional\n",
      "            User-supplied function to call after each iteration.  It is called\n",
      "            as callback(xk), where xk is the current solution vector.\n",
      "        m : int, optional\n",
      "            Number of inner FGMRES iterations per each outer iteration.\n",
      "            Default: 20\n",
      "        k : int, optional\n",
      "            Number of vectors to carry between inner FGMRES iterations.\n",
      "            According to [2]_, good values are around m.\n",
      "            Default: m\n",
      "        CU : list of tuples, optional\n",
      "            List of tuples ``(c, u)`` which contain the columns of the matrices\n",
      "            C and U in the GCROT(m,k) algorithm. For details, see [2]_.\n",
      "            The list given and vectors contained in it are modified in-place.\n",
      "            If not given, start from empty matrices. The ``c`` elements in the\n",
      "            tuples can be ``None``, in which case the vectors are recomputed\n",
      "            via ``c = A u`` on start and orthogonalized as described in [3]_.\n",
      "        discard_C : bool, optional\n",
      "            Discard the C-vectors at the end. Useful if recycling Krylov subspaces\n",
      "            for different linear systems.\n",
      "        truncate : {'oldest', 'smallest'}, optional\n",
      "            Truncation scheme to use. Drop: oldest vectors, or vectors with\n",
      "            smallest singular values using the scheme discussed in [1,2].\n",
      "            See [2]_ for detailed comparison.\n",
      "            Default: 'oldest'\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : ndarray\n",
      "            The solution found.\n",
      "        info : int\n",
      "            Provides convergence information:\n",
      "        \n",
      "            * 0  : successful exit\n",
      "            * >0 : convergence to tolerance not achieved, number of iterations\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import gcrotmk\n",
      "        >>> R = np.random.randn(5, 5)\n",
      "        >>> A = csc_matrix(R)\n",
      "        >>> b = np.random.randn(5)\n",
      "        >>> x, exit_code = gcrotmk(A, b)\n",
      "        >>> print(exit_code)\n",
      "        0\n",
      "        >>> np.allclose(A.dot(x), b)\n",
      "        True\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] E. de Sturler, ''Truncation strategies for optimal Krylov subspace\n",
      "               methods'', SIAM J. Numer. Anal. 36, 864 (1999).\n",
      "        .. [2] J.E. Hicken and D.W. Zingg, ''A simplified and flexible variant\n",
      "               of GCROT for solving nonsymmetric linear systems'',\n",
      "               SIAM J. Sci. Comput. 32, 172 (2010).\n",
      "        .. [3] M.L. Parks, E. de Sturler, G. Mackey, D.D. Johnson, S. Maiti,\n",
      "               ''Recycling Krylov subspaces for sequences of linear systems'',\n",
      "               SIAM J. Sci. Comput. 28, 1651 (2006).\n",
      "    \n",
      "    gmres(A, b, x0=None, tol=1e-05, restart=None, maxiter=None, M=None, callback=None, restrt=None, atol=None, callback_type=None)\n",
      "        Use Generalized Minimal RESidual iteration to solve ``Ax = b``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, ndarray, LinearOperator}\n",
      "            The real or complex N-by-N matrix of the linear system.\n",
      "            Alternatively, ``A`` can be a linear operator which can\n",
      "            produce ``Ax`` using, e.g.,\n",
      "            ``scipy.sparse.linalg.LinearOperator``.\n",
      "        b : ndarray\n",
      "            Right hand side of the linear system. Has shape (N,) or (N,1).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : ndarray\n",
      "            The converged solution.\n",
      "        info : int\n",
      "            Provides convergence information:\n",
      "              * 0  : successful exit\n",
      "              * >0 : convergence to tolerance not achieved, number of iterations\n",
      "              * <0 : illegal input or breakdown\n",
      "        \n",
      "        Other parameters\n",
      "        ----------------\n",
      "        x0 : ndarray\n",
      "            Starting guess for the solution (a vector of zeros by default).\n",
      "        tol, atol : float, optional\n",
      "            Tolerances for convergence, ``norm(residual) <= max(tol*norm(b), atol)``.\n",
      "            The default for ``atol`` is ``'legacy'``, which emulates\n",
      "            a different legacy behavior.\n",
      "        \n",
      "            .. warning::\n",
      "        \n",
      "               The default value for `atol` will be changed in a future release.\n",
      "               For future compatibility, specify `atol` explicitly.\n",
      "        restart : int, optional\n",
      "            Number of iterations between restarts. Larger values increase\n",
      "            iteration cost, but may be necessary for convergence.\n",
      "            Default is 20.\n",
      "        maxiter : int, optional\n",
      "            Maximum number of iterations (restart cycles).  Iteration will stop\n",
      "            after maxiter steps even if the specified tolerance has not been\n",
      "            achieved.\n",
      "        M : {sparse matrix, ndarray, LinearOperator}\n",
      "            Inverse of the preconditioner of A.  M should approximate the\n",
      "            inverse of A and be easy to solve for (see Notes).  Effective\n",
      "            preconditioning dramatically improves the rate of convergence,\n",
      "            which implies that fewer iterations are needed to reach a given\n",
      "            error tolerance.  By default, no preconditioner is used.\n",
      "        callback : function\n",
      "            User-supplied function to call after each iteration.  It is called\n",
      "            as `callback(args)`, where `args` are selected by `callback_type`.\n",
      "        callback_type : {'x', 'pr_norm', 'legacy'}, optional\n",
      "            Callback function argument requested:\n",
      "              - ``x``: current iterate (ndarray), called on every restart\n",
      "              - ``pr_norm``: relative (preconditioned) residual norm (float),\n",
      "                called on every inner iteration\n",
      "              - ``legacy`` (default): same as ``pr_norm``, but also changes the\n",
      "                meaning of 'maxiter' to count inner iterations instead of restart\n",
      "                cycles.\n",
      "        restrt : int, optional\n",
      "            DEPRECATED - use `restart` instead.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        LinearOperator\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        A preconditioner, P, is chosen such that P is close to A but easy to solve\n",
      "        for. The preconditioner parameter required by this routine is\n",
      "        ``M = P^-1``. The inverse should preferably not be calculated\n",
      "        explicitly.  Rather, use the following template to produce M::\n",
      "        \n",
      "          # Construct a linear operator that computes P^-1 @ x.\n",
      "          import scipy.sparse.linalg as spla\n",
      "          M_x = lambda x: spla.spsolve(P, x)\n",
      "          M = spla.LinearOperator((n, n), M_x)\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import gmres\n",
      "        >>> A = csc_matrix([[3, 2, 0], [1, -1, 0], [0, 5, 1]], dtype=float)\n",
      "        >>> b = np.array([2, 4, -1], dtype=float)\n",
      "        >>> x, exitCode = gmres(A, b)\n",
      "        >>> print(exitCode)            # 0 indicates successful convergence\n",
      "        0\n",
      "        >>> np.allclose(A.dot(x), b)\n",
      "        True\n",
      "    \n",
      "    inv(A)\n",
      "        Compute the inverse of a sparse matrix\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : (M, M) sparse matrix\n",
      "            square matrix to be inverted\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        Ainv : (M, M) sparse matrix\n",
      "            inverse of `A`\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This computes the sparse inverse of `A`. If the inverse of `A` is expected\n",
      "        to be non-sparse, it will likely be faster to convert `A` to dense and use\n",
      "        `scipy.linalg.inv`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import inv\n",
      "        >>> A = csc_matrix([[1., 0.], [1., 2.]])\n",
      "        >>> Ainv = inv(A)\n",
      "        >>> Ainv\n",
      "        <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "            with 3 stored elements in Compressed Sparse Column format>\n",
      "        >>> A.dot(Ainv)\n",
      "        <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "            with 2 stored elements in Compressed Sparse Column format>\n",
      "        >>> A.dot(Ainv).toarray()\n",
      "        array([[ 1.,  0.],\n",
      "               [ 0.,  1.]])\n",
      "        \n",
      "        .. versionadded:: 0.12.0\n",
      "    \n",
      "    lgmres(A, b, x0=None, tol=1e-05, maxiter=1000, M=None, callback=None, inner_m=30, outer_k=3, outer_v=None, store_outer_Av=True, prepend_outer_v=False, atol=None)\n",
      "        Solve a matrix equation using the LGMRES algorithm.\n",
      "        \n",
      "        The LGMRES algorithm [1]_ [2]_ is designed to avoid some problems\n",
      "        in the convergence in restarted GMRES, and often converges in fewer\n",
      "        iterations.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, ndarray, LinearOperator}\n",
      "            The real or complex N-by-N matrix of the linear system.\n",
      "            Alternatively, ``A`` can be a linear operator which can\n",
      "            produce ``Ax`` using, e.g.,\n",
      "            ``scipy.sparse.linalg.LinearOperator``.\n",
      "        b : ndarray\n",
      "            Right hand side of the linear system. Has shape (N,) or (N,1).\n",
      "        x0 : ndarray\n",
      "            Starting guess for the solution.\n",
      "        tol, atol : float, optional\n",
      "            Tolerances for convergence, ``norm(residual) <= max(tol*norm(b), atol)``.\n",
      "            The default for ``atol`` is `tol`.\n",
      "        \n",
      "            .. warning::\n",
      "        \n",
      "               The default value for `atol` will be changed in a future release.\n",
      "               For future compatibility, specify `atol` explicitly.\n",
      "        maxiter : int, optional\n",
      "            Maximum number of iterations.  Iteration will stop after maxiter\n",
      "            steps even if the specified tolerance has not been achieved.\n",
      "        M : {sparse matrix, ndarray, LinearOperator}, optional\n",
      "            Preconditioner for A.  The preconditioner should approximate the\n",
      "            inverse of A.  Effective preconditioning dramatically improves the\n",
      "            rate of convergence, which implies that fewer iterations are needed\n",
      "            to reach a given error tolerance.\n",
      "        callback : function, optional\n",
      "            User-supplied function to call after each iteration.  It is called\n",
      "            as callback(xk), where xk is the current solution vector.\n",
      "        inner_m : int, optional\n",
      "            Number of inner GMRES iterations per each outer iteration.\n",
      "        outer_k : int, optional\n",
      "            Number of vectors to carry between inner GMRES iterations.\n",
      "            According to [1]_, good values are in the range of 1...3.\n",
      "            However, note that if you want to use the additional vectors to\n",
      "            accelerate solving multiple similar problems, larger values may\n",
      "            be beneficial.\n",
      "        outer_v : list of tuples, optional\n",
      "            List containing tuples ``(v, Av)`` of vectors and corresponding\n",
      "            matrix-vector products, used to augment the Krylov subspace, and\n",
      "            carried between inner GMRES iterations. The element ``Av`` can\n",
      "            be `None` if the matrix-vector product should be re-evaluated.\n",
      "            This parameter is modified in-place by `lgmres`, and can be used\n",
      "            to pass \"guess\" vectors in and out of the algorithm when solving\n",
      "            similar problems.\n",
      "        store_outer_Av : bool, optional\n",
      "            Whether LGMRES should store also A@v in addition to vectors `v`\n",
      "            in the `outer_v` list. Default is True.\n",
      "        prepend_outer_v : bool, optional\n",
      "            Whether to put outer_v augmentation vectors before Krylov iterates.\n",
      "            In standard LGMRES, prepend_outer_v=False.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : ndarray\n",
      "            The converged solution.\n",
      "        info : int\n",
      "            Provides convergence information:\n",
      "        \n",
      "                - 0  : successful exit\n",
      "                - >0 : convergence to tolerance not achieved, number of iterations\n",
      "                - <0 : illegal input or breakdown\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The LGMRES algorithm [1]_ [2]_ is designed to avoid the\n",
      "        slowing of convergence in restarted GMRES, due to alternating\n",
      "        residual vectors. Typically, it often outperforms GMRES(m) of\n",
      "        comparable memory requirements by some measure, or at least is not\n",
      "        much worse.\n",
      "        \n",
      "        Another advantage in this algorithm is that you can supply it with\n",
      "        'guess' vectors in the `outer_v` argument that augment the Krylov\n",
      "        subspace. If the solution lies close to the span of these vectors,\n",
      "        the algorithm converges faster. This can be useful if several very\n",
      "        similar matrices need to be inverted one after another, such as in\n",
      "        Newton-Krylov iteration where the Jacobian matrix often changes\n",
      "        little in the nonlinear steps.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] A.H. Baker and E.R. Jessup and T. Manteuffel, \"A Technique for\n",
      "                 Accelerating the Convergence of Restarted GMRES\", SIAM J. Matrix\n",
      "                 Anal. Appl. 26, 962 (2005).\n",
      "        .. [2] A.H. Baker, \"On Improving the Performance of the Linear Solver\n",
      "                 restarted GMRES\", PhD thesis, University of Colorado (2003).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import lgmres\n",
      "        >>> A = csc_matrix([[3, 2, 0], [1, -1, 0], [0, 5, 1]], dtype=float)\n",
      "        >>> b = np.array([2, 4, -1], dtype=float)\n",
      "        >>> x, exitCode = lgmres(A, b)\n",
      "        >>> print(exitCode)            # 0 indicates successful convergence\n",
      "        0\n",
      "        >>> np.allclose(A.dot(x), b)\n",
      "        True\n",
      "    \n",
      "    lobpcg(A, X, B=None, M=None, Y=None, tol=None, maxiter=None, largest=True, verbosityLevel=0, retLambdaHistory=False, retResidualNormsHistory=False)\n",
      "        Locally Optimal Block Preconditioned Conjugate Gradient Method (LOBPCG)\n",
      "        \n",
      "        LOBPCG is a preconditioned eigensolver for large symmetric positive\n",
      "        definite (SPD) generalized eigenproblems.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, dense matrix, LinearOperator}\n",
      "            The symmetric linear operator of the problem, usually a\n",
      "            sparse matrix.  Often called the \"stiffness matrix\".\n",
      "        X : ndarray, float32 or float64\n",
      "            Initial approximation to the ``k`` eigenvectors (non-sparse). If `A`\n",
      "            has ``shape=(n,n)`` then `X` should have shape ``shape=(n,k)``.\n",
      "        B : {dense matrix, sparse matrix, LinearOperator}, optional\n",
      "            The right hand side operator in a generalized eigenproblem.\n",
      "            By default, ``B = Identity``.  Often called the \"mass matrix\".\n",
      "        M : {dense matrix, sparse matrix, LinearOperator}, optional\n",
      "            Preconditioner to `A`; by default ``M = Identity``.\n",
      "            `M` should approximate the inverse of `A`.\n",
      "        Y : ndarray, float32 or float64, optional\n",
      "            n-by-sizeY matrix of constraints (non-sparse), sizeY < n\n",
      "            The iterations will be performed in the B-orthogonal complement\n",
      "            of the column-space of Y. Y must be full rank.\n",
      "        tol : scalar, optional\n",
      "            Solver tolerance (stopping criterion).\n",
      "            The default is ``tol=n*sqrt(eps)``.\n",
      "        maxiter : int, optional\n",
      "            Maximum number of iterations.  The default is ``maxiter = 20``.\n",
      "        largest : bool, optional\n",
      "            When True, solve for the largest eigenvalues, otherwise the smallest.\n",
      "        verbosityLevel : int, optional\n",
      "            Controls solver output.  The default is ``verbosityLevel=0``.\n",
      "        retLambdaHistory : bool, optional\n",
      "            Whether to return eigenvalue history.  Default is False.\n",
      "        retResidualNormsHistory : bool, optional\n",
      "            Whether to return history of residual norms.  Default is False.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        w : ndarray\n",
      "            Array of ``k`` eigenvalues\n",
      "        v : ndarray\n",
      "            An array of ``k`` eigenvectors.  `v` has the same shape as `X`.\n",
      "        lambdas : list of ndarray, optional\n",
      "            The eigenvalue history, if `retLambdaHistory` is True.\n",
      "        rnorms : list of ndarray, optional\n",
      "            The history of residual norms, if `retResidualNormsHistory` is True.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        If both ``retLambdaHistory`` and ``retResidualNormsHistory`` are True,\n",
      "        the return tuple has the following format\n",
      "        ``(lambda, V, lambda history, residual norms history)``.\n",
      "        \n",
      "        In the following ``n`` denotes the matrix size and ``k`` the number\n",
      "        of required eigenvalues (smallest or largest).\n",
      "        \n",
      "        The LOBPCG code internally solves eigenproblems of the size ``3k`` on every\n",
      "        iteration by calling the \"standard\" dense eigensolver, so if ``k`` is not\n",
      "        small enough compared to ``n``, it does not make sense to call the LOBPCG\n",
      "        code, but rather one should use the \"standard\" eigensolver, e.g. numpy or\n",
      "        scipy function in this case.\n",
      "        If one calls the LOBPCG algorithm for ``5k > n``, it will most likely break\n",
      "        internally, so the code tries to call the standard function instead.\n",
      "        \n",
      "        It is not that ``n`` should be large for the LOBPCG to work, but rather the\n",
      "        ratio ``n / k`` should be large. It you call LOBPCG with ``k=1``\n",
      "        and ``n=10``, it works though ``n`` is small. The method is intended\n",
      "        for extremely large ``n / k``.\n",
      "        \n",
      "        The convergence speed depends basically on two factors:\n",
      "        \n",
      "        1. Relative separation of the seeking eigenvalues from the rest\n",
      "           of the eigenvalues. One can vary ``k`` to improve the absolute\n",
      "           separation and use proper preconditioning to shrink the spectral spread.\n",
      "           For example, a rod vibration test problem (under tests\n",
      "           directory) is ill-conditioned for large ``n``, so convergence will be\n",
      "           slow, unless efficient preconditioning is used. For this specific\n",
      "           problem, a good simple preconditioner function would be a linear solve\n",
      "           for `A`, which is easy to code since `A` is tridiagonal.\n",
      "        \n",
      "        2. Quality of the initial approximations `X` to the seeking eigenvectors.\n",
      "           Randomly distributed around the origin vectors work well if no better\n",
      "           choice is known.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] A. V. Knyazev (2001),\n",
      "               Toward the Optimal Preconditioned Eigensolver: Locally Optimal\n",
      "               Block Preconditioned Conjugate Gradient Method.\n",
      "               SIAM Journal on Scientific Computing 23, no. 2,\n",
      "               pp. 517-541. :doi:`10.1137/S1064827500366124`\n",
      "        \n",
      "        .. [2] A. V. Knyazev, I. Lashuk, M. E. Argentati, and E. Ovchinnikov\n",
      "               (2007), Block Locally Optimal Preconditioned Eigenvalue Xolvers\n",
      "               (BLOPEX) in hypre and PETSc. :arxiv:`0705.2626`\n",
      "        \n",
      "        .. [3] A. V. Knyazev's C and MATLAB implementations:\n",
      "               https://github.com/lobpcg/blopex\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        \n",
      "        Solve ``A x = lambda x`` with constraints and preconditioning.\n",
      "        \n",
      "        >>> import numpy as np\n",
      "        >>> from scipy.sparse import spdiags, issparse\n",
      "        >>> from scipy.sparse.linalg import lobpcg, LinearOperator\n",
      "        \n",
      "        The square matrix size:\n",
      "        \n",
      "        >>> n = 100\n",
      "        >>> vals = np.arange(1, n + 1)\n",
      "        \n",
      "        The first mandatory input parameter, in this test\n",
      "        a sparse 2D array representing the square matrix\n",
      "        of the eigenvalue problem to solve:\n",
      "        \n",
      "        >>> A = spdiags(vals, 0, n, n)\n",
      "        >>> A.toarray()\n",
      "        array([[  1.,   0.,   0., ...,   0.,   0.,   0.],\n",
      "               [  0.,   2.,   0., ...,   0.,   0.,   0.],\n",
      "               [  0.,   0.,   3., ...,   0.,   0.,   0.],\n",
      "               ...,\n",
      "               [  0.,   0.,   0., ...,  98.,   0.,   0.],\n",
      "               [  0.,   0.,   0., ...,   0.,  99.,   0.],\n",
      "               [  0.,   0.,   0., ...,   0.,   0., 100.]])\n",
      "        \n",
      "        Initial guess for eigenvectors, should have linearly independent\n",
      "        columns. The second mandatory input parameter, a 2D array with the\n",
      "        row dimension determining the number of requested eigenvalues.\n",
      "        If no initial approximations available, randomly oriented vectors\n",
      "        commonly work best, e.g., with components normally disrtibuted\n",
      "        around zero or uniformly distributed on the interval [-1 1].\n",
      "        \n",
      "        >>> rng = np.random.default_rng()\n",
      "        >>> X = rng.normal(size=(n, 3))\n",
      "        \n",
      "        Constraints - an optional input parameter is a 2D array comprising\n",
      "        of column vectors that the eigenvectors must be orthogonal to:\n",
      "        \n",
      "        >>> Y = np.eye(n, 3)\n",
      "        \n",
      "        Preconditioner in the inverse of A in this example:\n",
      "        \n",
      "        >>> invA = spdiags([1./vals], 0, n, n)\n",
      "        \n",
      "        The preconditiner must be defined by a function:\n",
      "        \n",
      "        >>> def precond( x ):\n",
      "        ...     return invA @ x\n",
      "        \n",
      "        The argument x of the preconditioner function is a matrix inside `lobpcg`,\n",
      "        thus the use of matrix-matrix product ``@``.\n",
      "        \n",
      "        The preconditioner function is passed to lobpcg as a `LinearOperator`:\n",
      "        \n",
      "        >>> M = LinearOperator(matvec=precond, matmat=precond,\n",
      "        ...                    shape=(n, n), dtype=np.float64)\n",
      "        \n",
      "        Let us now solve the eigenvalue problem for the matrix A:\n",
      "        \n",
      "        >>> eigenvalues, _ = lobpcg(A, X, Y=Y, M=M, largest=False)\n",
      "        >>> eigenvalues\n",
      "        array([4., 5., 6.])\n",
      "        \n",
      "        Note that the vectors passed in Y are the eigenvectors of the 3 smallest\n",
      "        eigenvalues. The results returned are orthogonal to those.\n",
      "    \n",
      "    lsmr(A, b, damp=0.0, atol=1e-06, btol=1e-06, conlim=100000000.0, maxiter=None, show=False, x0=None)\n",
      "        Iterative solver for least-squares problems.\n",
      "        \n",
      "        lsmr solves the system of linear equations ``Ax = b``. If the system\n",
      "        is inconsistent, it solves the least-squares problem ``min ||b - Ax||_2``.\n",
      "        ``A`` is a rectangular matrix of dimension m-by-n, where all cases are\n",
      "        allowed: m = n, m > n, or m < n. ``b`` is a vector of length m.\n",
      "        The matrix A may be dense or sparse (usually sparse).\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, ndarray, LinearOperator}\n",
      "            Matrix A in the linear system.\n",
      "            Alternatively, ``A`` can be a linear operator which can\n",
      "            produce ``Ax`` and ``A^H x`` using, e.g.,\n",
      "            ``scipy.sparse.linalg.LinearOperator``.\n",
      "        b : array_like, shape (m,)\n",
      "            Vector ``b`` in the linear system.\n",
      "        damp : float\n",
      "            Damping factor for regularized least-squares. `lsmr` solves\n",
      "            the regularized least-squares problem::\n",
      "        \n",
      "             min ||(b) - (  A   )x||\n",
      "                 ||(0)   (damp*I) ||_2\n",
      "        \n",
      "            where damp is a scalar.  If damp is None or 0, the system\n",
      "            is solved without regularization. Default is 0.\n",
      "        atol, btol : float, optional\n",
      "            Stopping tolerances. `lsmr` continues iterations until a\n",
      "            certain backward error estimate is smaller than some quantity\n",
      "            depending on atol and btol.  Let ``r = b - Ax`` be the\n",
      "            residual vector for the current approximate solution ``x``.\n",
      "            If ``Ax = b`` seems to be consistent, `lsmr` terminates\n",
      "            when ``norm(r) <= atol * norm(A) * norm(x) + btol * norm(b)``.\n",
      "            Otherwise, `lsmr` terminates when ``norm(A^H r) <=\n",
      "            atol * norm(A) * norm(r)``.  If both tolerances are 1.0e-6 (default),\n",
      "            the final ``norm(r)`` should be accurate to about 6\n",
      "            digits. (The final ``x`` will usually have fewer correct digits,\n",
      "            depending on ``cond(A)`` and the size of LAMBDA.)  If `atol`\n",
      "            or `btol` is None, a default value of 1.0e-6 will be used.\n",
      "            Ideally, they should be estimates of the relative error in the\n",
      "            entries of ``A`` and ``b`` respectively.  For example, if the entries\n",
      "            of ``A`` have 7 correct digits, set ``atol = 1e-7``. This prevents\n",
      "            the algorithm from doing unnecessary work beyond the\n",
      "            uncertainty of the input data.\n",
      "        conlim : float, optional\n",
      "            `lsmr` terminates if an estimate of ``cond(A)`` exceeds\n",
      "            `conlim`.  For compatible systems ``Ax = b``, conlim could be\n",
      "            as large as 1.0e+12 (say).  For least-squares problems,\n",
      "            `conlim` should be less than 1.0e+8. If `conlim` is None, the\n",
      "            default value is 1e+8.  Maximum precision can be obtained by\n",
      "            setting ``atol = btol = conlim = 0``, but the number of\n",
      "            iterations may then be excessive. Default is 1e8.\n",
      "        maxiter : int, optional\n",
      "            `lsmr` terminates if the number of iterations reaches\n",
      "            `maxiter`.  The default is ``maxiter = min(m, n)``.  For\n",
      "            ill-conditioned systems, a larger value of `maxiter` may be\n",
      "            needed. Default is False.\n",
      "        show : bool, optional\n",
      "            Print iterations logs if ``show=True``. Default is False.\n",
      "        x0 : array_like, shape (n,), optional\n",
      "            Initial guess of ``x``, if None zeros are used. Default is None.\n",
      "        \n",
      "            .. versionadded:: 1.0.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : ndarray of float\n",
      "            Least-square solution returned.\n",
      "        istop : int\n",
      "            istop gives the reason for stopping::\n",
      "        \n",
      "              istop   = 0 means x=0 is a solution.  If x0 was given, then x=x0 is a\n",
      "                          solution.\n",
      "                      = 1 means x is an approximate solution to A@x = B,\n",
      "                          according to atol and btol.\n",
      "                      = 2 means x approximately solves the least-squares problem\n",
      "                          according to atol.\n",
      "                      = 3 means COND(A) seems to be greater than CONLIM.\n",
      "                      = 4 is the same as 1 with atol = btol = eps (machine\n",
      "                          precision)\n",
      "                      = 5 is the same as 2 with atol = eps.\n",
      "                      = 6 is the same as 3 with CONLIM = 1/eps.\n",
      "                      = 7 means ITN reached maxiter before the other stopping\n",
      "                          conditions were satisfied.\n",
      "        \n",
      "        itn : int\n",
      "            Number of iterations used.\n",
      "        normr : float\n",
      "            ``norm(b-Ax)``\n",
      "        normar : float\n",
      "            ``norm(A^H (b - Ax))``\n",
      "        norma : float\n",
      "            ``norm(A)``\n",
      "        conda : float\n",
      "            Condition number of A.\n",
      "        normx : float\n",
      "            ``norm(x)``\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionadded:: 0.11.0\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] D. C.-L. Fong and M. A. Saunders,\n",
      "               \"LSMR: An iterative algorithm for sparse least-squares problems\",\n",
      "               SIAM J. Sci. Comput., vol. 33, pp. 2950-2971, 2011.\n",
      "               :arxiv:`1006.0758`\n",
      "        .. [2] LSMR Software, https://web.stanford.edu/group/SOL/software/lsmr/\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import lsmr\n",
      "        >>> A = csc_matrix([[1., 0.], [1., 1.], [0., 1.]], dtype=float)\n",
      "        \n",
      "        The first example has the trivial solution ``[0, 0]``\n",
      "        \n",
      "        >>> b = np.array([0., 0., 0.], dtype=float)\n",
      "        >>> x, istop, itn, normr = lsmr(A, b)[:4]\n",
      "        >>> istop\n",
      "        0\n",
      "        >>> x\n",
      "        array([0., 0.])\n",
      "        \n",
      "        The stopping code `istop=0` returned indicates that a vector of zeros was\n",
      "        found as a solution. The returned solution `x` indeed contains\n",
      "        ``[0., 0.]``. The next example has a non-trivial solution:\n",
      "        \n",
      "        >>> b = np.array([1., 0., -1.], dtype=float)\n",
      "        >>> x, istop, itn, normr = lsmr(A, b)[:4]\n",
      "        >>> istop\n",
      "        1\n",
      "        >>> x\n",
      "        array([ 1., -1.])\n",
      "        >>> itn\n",
      "        1\n",
      "        >>> normr\n",
      "        4.440892098500627e-16\n",
      "        \n",
      "        As indicated by `istop=1`, `lsmr` found a solution obeying the tolerance\n",
      "        limits. The given solution ``[1., -1.]`` obviously solves the equation. The\n",
      "        remaining return values include information about the number of iterations\n",
      "        (`itn=1`) and the remaining difference of left and right side of the solved\n",
      "        equation.\n",
      "        The final example demonstrates the behavior in the case where there is no\n",
      "        solution for the equation:\n",
      "        \n",
      "        >>> b = np.array([1., 0.01, -1.], dtype=float)\n",
      "        >>> x, istop, itn, normr = lsmr(A, b)[:4]\n",
      "        >>> istop\n",
      "        2\n",
      "        >>> x\n",
      "        array([ 1.00333333, -0.99666667])\n",
      "        >>> A.dot(x)-b\n",
      "        array([ 0.00333333, -0.00333333,  0.00333333])\n",
      "        >>> normr\n",
      "        0.005773502691896255\n",
      "        \n",
      "        `istop` indicates that the system is inconsistent and thus `x` is rather an\n",
      "        approximate solution to the corresponding least-squares problem. `normr`\n",
      "        contains the minimal distance that was found.\n",
      "    \n",
      "    lsqr(A, b, damp=0.0, atol=1e-06, btol=1e-06, conlim=100000000.0, iter_lim=None, show=False, calc_var=False, x0=None)\n",
      "        Find the least-squares solution to a large, sparse, linear system\n",
      "        of equations.\n",
      "        \n",
      "        The function solves ``Ax = b``  or  ``min ||Ax - b||^2`` or\n",
      "        ``min ||Ax - b||^2 + d^2 ||x - x0||^2``.\n",
      "        \n",
      "        The matrix A may be square or rectangular (over-determined or\n",
      "        under-determined), and may have any rank.\n",
      "        \n",
      "        ::\n",
      "        \n",
      "          1. Unsymmetric equations --    solve  Ax = b\n",
      "        \n",
      "          2. Linear least squares  --    solve  Ax = b\n",
      "                                         in the least-squares sense\n",
      "        \n",
      "          3. Damped least squares  --    solve  (   A    )*x = (    b    )\n",
      "                                                ( damp*I )     ( damp*x0 )\n",
      "                                         in the least-squares sense\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, ndarray, LinearOperator}\n",
      "            Representation of an m-by-n matrix.\n",
      "            Alternatively, ``A`` can be a linear operator which can\n",
      "            produce ``Ax`` and ``A^T x`` using, e.g.,\n",
      "            ``scipy.sparse.linalg.LinearOperator``.\n",
      "        b : array_like, shape (m,)\n",
      "            Right-hand side vector ``b``.\n",
      "        damp : float\n",
      "            Damping coefficient. Default is 0.\n",
      "        atol, btol : float, optional\n",
      "            Stopping tolerances. `lsqr` continues iterations until a\n",
      "            certain backward error estimate is smaller than some quantity\n",
      "            depending on atol and btol.  Let ``r = b - Ax`` be the\n",
      "            residual vector for the current approximate solution ``x``.\n",
      "            If ``Ax = b`` seems to be consistent, `lsqr` terminates\n",
      "            when ``norm(r) <= atol * norm(A) * norm(x) + btol * norm(b)``.\n",
      "            Otherwise, `lsqr` terminates when ``norm(A^H r) <=\n",
      "            atol * norm(A) * norm(r)``.  If both tolerances are 1.0e-6 (default),\n",
      "            the final ``norm(r)`` should be accurate to about 6\n",
      "            digits. (The final ``x`` will usually have fewer correct digits,\n",
      "            depending on ``cond(A)`` and the size of LAMBDA.)  If `atol`\n",
      "            or `btol` is None, a default value of 1.0e-6 will be used.\n",
      "            Ideally, they should be estimates of the relative error in the\n",
      "            entries of ``A`` and ``b`` respectively.  For example, if the entries\n",
      "            of ``A`` have 7 correct digits, set ``atol = 1e-7``. This prevents\n",
      "            the algorithm from doing unnecessary work beyond the\n",
      "            uncertainty of the input data.\n",
      "        conlim : float, optional\n",
      "            Another stopping tolerance.  lsqr terminates if an estimate of\n",
      "            ``cond(A)`` exceeds `conlim`.  For compatible systems ``Ax =\n",
      "            b``, `conlim` could be as large as 1.0e+12 (say).  For\n",
      "            least-squares problems, conlim should be less than 1.0e+8.\n",
      "            Maximum precision can be obtained by setting ``atol = btol =\n",
      "            conlim = zero``, but the number of iterations may then be\n",
      "            excessive. Default is 1e8.\n",
      "        iter_lim : int, optional\n",
      "            Explicit limitation on number of iterations (for safety).\n",
      "        show : bool, optional\n",
      "            Display an iteration log. Default is False.\n",
      "        calc_var : bool, optional\n",
      "            Whether to estimate diagonals of ``(A'A + damp^2*I)^{-1}``.\n",
      "        x0 : array_like, shape (n,), optional\n",
      "            Initial guess of x, if None zeros are used. Default is None.\n",
      "        \n",
      "            .. versionadded:: 1.0.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : ndarray of float\n",
      "            The final solution.\n",
      "        istop : int\n",
      "            Gives the reason for termination.\n",
      "            1 means x is an approximate solution to Ax = b.\n",
      "            2 means x approximately solves the least-squares problem.\n",
      "        itn : int\n",
      "            Iteration number upon termination.\n",
      "        r1norm : float\n",
      "            ``norm(r)``, where ``r = b - Ax``.\n",
      "        r2norm : float\n",
      "            ``sqrt( norm(r)^2  +  damp^2 * norm(x - x0)^2 )``.  Equal to `r1norm`\n",
      "            if ``damp == 0``.\n",
      "        anorm : float\n",
      "            Estimate of Frobenius norm of ``Abar = [[A]; [damp*I]]``.\n",
      "        acond : float\n",
      "            Estimate of ``cond(Abar)``.\n",
      "        arnorm : float\n",
      "            Estimate of ``norm(A'@r - damp^2*(x - x0))``.\n",
      "        xnorm : float\n",
      "            ``norm(x)``\n",
      "        var : ndarray of float\n",
      "            If ``calc_var`` is True, estimates all diagonals of\n",
      "            ``(A'A)^{-1}`` (if ``damp == 0``) or more generally ``(A'A +\n",
      "            damp^2*I)^{-1}``.  This is well defined if A has full column\n",
      "            rank or ``damp > 0``.  (Not sure what var means if ``rank(A)\n",
      "            < n`` and ``damp = 0.``)\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        LSQR uses an iterative method to approximate the solution.  The\n",
      "        number of iterations required to reach a certain accuracy depends\n",
      "        strongly on the scaling of the problem.  Poor scaling of the rows\n",
      "        or columns of A should therefore be avoided where possible.\n",
      "        \n",
      "        For example, in problem 1 the solution is unaltered by\n",
      "        row-scaling.  If a row of A is very small or large compared to\n",
      "        the other rows of A, the corresponding row of ( A  b ) should be\n",
      "        scaled up or down.\n",
      "        \n",
      "        In problems 1 and 2, the solution x is easily recovered\n",
      "        following column-scaling.  Unless better information is known,\n",
      "        the nonzero columns of A should be scaled so that they all have\n",
      "        the same Euclidean norm (e.g., 1.0).\n",
      "        \n",
      "        In problem 3, there is no freedom to re-scale if damp is\n",
      "        nonzero.  However, the value of damp should be assigned only\n",
      "        after attention has been paid to the scaling of A.\n",
      "        \n",
      "        The parameter damp is intended to help regularize\n",
      "        ill-conditioned systems, by preventing the true solution from\n",
      "        being very large.  Another aid to regularization is provided by\n",
      "        the parameter acond, which may be used to terminate iterations\n",
      "        before the computed solution becomes very large.\n",
      "        \n",
      "        If some initial estimate ``x0`` is known and if ``damp == 0``,\n",
      "        one could proceed as follows:\n",
      "        \n",
      "          1. Compute a residual vector ``r0 = b - A@x0``.\n",
      "          2. Use LSQR to solve the system  ``A@dx = r0``.\n",
      "          3. Add the correction dx to obtain a final solution ``x = x0 + dx``.\n",
      "        \n",
      "        This requires that ``x0`` be available before and after the call\n",
      "        to LSQR.  To judge the benefits, suppose LSQR takes k1 iterations\n",
      "        to solve A@x = b and k2 iterations to solve A@dx = r0.\n",
      "        If x0 is \"good\", norm(r0) will be smaller than norm(b).\n",
      "        If the same stopping tolerances atol and btol are used for each\n",
      "        system, k1 and k2 will be similar, but the final solution x0 + dx\n",
      "        should be more accurate.  The only way to reduce the total work\n",
      "        is to use a larger stopping tolerance for the second system.\n",
      "        If some value btol is suitable for A@x = b, the larger value\n",
      "        btol*norm(b)/norm(r0)  should be suitable for A@dx = r0.\n",
      "        \n",
      "        Preconditioning is another way to reduce the number of iterations.\n",
      "        If it is possible to solve a related system ``M@x = b``\n",
      "        efficiently, where M approximates A in some helpful way (e.g. M -\n",
      "        A has low rank or its elements are small relative to those of A),\n",
      "        LSQR may converge more rapidly on the system ``A@M(inverse)@z =\n",
      "        b``, after which x can be recovered by solving M@x = z.\n",
      "        \n",
      "        If A is symmetric, LSQR should not be used!\n",
      "        \n",
      "        Alternatives are the symmetric conjugate-gradient method (cg)\n",
      "        and/or SYMMLQ.  SYMMLQ is an implementation of symmetric cg that\n",
      "        applies to any symmetric A and will converge more rapidly than\n",
      "        LSQR.  If A is positive definite, there are other implementations\n",
      "        of symmetric cg that require slightly less work per iteration than\n",
      "        SYMMLQ (but will take the same number of iterations).\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] C. C. Paige and M. A. Saunders (1982a).\n",
      "               \"LSQR: An algorithm for sparse linear equations and\n",
      "               sparse least squares\", ACM TOMS 8(1), 43-71.\n",
      "        .. [2] C. C. Paige and M. A. Saunders (1982b).\n",
      "               \"Algorithm 583.  LSQR: Sparse linear equations and least\n",
      "               squares problems\", ACM TOMS 8(2), 195-209.\n",
      "        .. [3] M. A. Saunders (1995).  \"Solution of sparse rectangular\n",
      "               systems using LSQR and CRAIG\", BIT 35, 588-604.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import lsqr\n",
      "        >>> A = csc_matrix([[1., 0.], [1., 1.], [0., 1.]], dtype=float)\n",
      "        \n",
      "        The first example has the trivial solution ``[0, 0]``\n",
      "        \n",
      "        >>> b = np.array([0., 0., 0.], dtype=float)\n",
      "        >>> x, istop, itn, normr = lsqr(A, b)[:4]\n",
      "        >>> istop\n",
      "        0\n",
      "        >>> x\n",
      "        array([ 0.,  0.])\n",
      "        \n",
      "        The stopping code `istop=0` returned indicates that a vector of zeros was\n",
      "        found as a solution. The returned solution `x` indeed contains\n",
      "        ``[0., 0.]``. The next example has a non-trivial solution:\n",
      "        \n",
      "        >>> b = np.array([1., 0., -1.], dtype=float)\n",
      "        >>> x, istop, itn, r1norm = lsqr(A, b)[:4]\n",
      "        >>> istop\n",
      "        1\n",
      "        >>> x\n",
      "        array([ 1., -1.])\n",
      "        >>> itn\n",
      "        1\n",
      "        >>> r1norm\n",
      "        4.440892098500627e-16\n",
      "        \n",
      "        As indicated by `istop=1`, `lsqr` found a solution obeying the tolerance\n",
      "        limits. The given solution ``[1., -1.]`` obviously solves the equation. The\n",
      "        remaining return values include information about the number of iterations\n",
      "        (`itn=1`) and the remaining difference of left and right side of the solved\n",
      "        equation.\n",
      "        The final example demonstrates the behavior in the case where there is no\n",
      "        solution for the equation:\n",
      "        \n",
      "        >>> b = np.array([1., 0.01, -1.], dtype=float)\n",
      "        >>> x, istop, itn, r1norm = lsqr(A, b)[:4]\n",
      "        >>> istop\n",
      "        2\n",
      "        >>> x\n",
      "        array([ 1.00333333, -0.99666667])\n",
      "        >>> A.dot(x)-b\n",
      "        array([ 0.00333333, -0.00333333,  0.00333333])\n",
      "        >>> r1norm\n",
      "        0.005773502691896255\n",
      "        \n",
      "        `istop` indicates that the system is inconsistent and thus `x` is rather an\n",
      "        approximate solution to the corresponding least-squares problem. `r1norm`\n",
      "        contains the norm of the minimal residual that was found.\n",
      "    \n",
      "    minres(A, b, x0=None, shift=0.0, tol=1e-05, maxiter=None, M=None, callback=None, show=False, check=False)\n",
      "        Use MINimum RESidual iteration to solve Ax=b\n",
      "        \n",
      "        MINRES minimizes norm(Ax - b) for a real symmetric matrix A.  Unlike\n",
      "        the Conjugate Gradient method, A can be indefinite or singular.\n",
      "        \n",
      "        If shift != 0 then the method solves (A - shift*I)x = b\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, ndarray, LinearOperator}\n",
      "            The real symmetric N-by-N matrix of the linear system\n",
      "            Alternatively, ``A`` can be a linear operator which can\n",
      "            produce ``Ax`` using, e.g.,\n",
      "            ``scipy.sparse.linalg.LinearOperator``.\n",
      "        b : ndarray\n",
      "            Right hand side of the linear system. Has shape (N,) or (N,1).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : ndarray\n",
      "            The converged solution.\n",
      "        info : integer\n",
      "            Provides convergence information:\n",
      "                0  : successful exit\n",
      "                >0 : convergence to tolerance not achieved, number of iterations\n",
      "                <0 : illegal input or breakdown\n",
      "        \n",
      "        Other Parameters\n",
      "        ----------------\n",
      "        x0 : ndarray\n",
      "            Starting guess for the solution.\n",
      "        shift : float\n",
      "            Value to apply to the system ``(A - shift * I)x = b``. Default is 0.\n",
      "        tol : float\n",
      "            Tolerance to achieve. The algorithm terminates when the relative\n",
      "            residual is below `tol`.\n",
      "        maxiter : integer\n",
      "            Maximum number of iterations.  Iteration will stop after maxiter\n",
      "            steps even if the specified tolerance has not been achieved.\n",
      "        M : {sparse matrix, ndarray, LinearOperator}\n",
      "            Preconditioner for A.  The preconditioner should approximate the\n",
      "            inverse of A.  Effective preconditioning dramatically improves the\n",
      "            rate of convergence, which implies that fewer iterations are needed\n",
      "            to reach a given error tolerance.\n",
      "        callback : function\n",
      "            User-supplied function to call after each iteration.  It is called\n",
      "            as callback(xk), where xk is the current solution vector.\n",
      "        show : bool\n",
      "            If ``True``, print out a summary and metrics related to the solution\n",
      "            during iterations. Default is ``False``.\n",
      "        check : bool\n",
      "            If ``True``, run additional input validation to check that `A` and\n",
      "            `M` (if specified) are symmetric. Default is ``False``.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import minres\n",
      "        >>> A = csc_matrix([[3, 2, 0], [1, -1, 0], [0, 5, 1]], dtype=float)\n",
      "        >>> A = A + A.T\n",
      "        >>> b = np.array([2, 4, -1], dtype=float)\n",
      "        >>> x, exitCode = minres(A, b)\n",
      "        >>> print(exitCode)            # 0 indicates successful convergence\n",
      "        0\n",
      "        >>> np.allclose(A.dot(x), b)\n",
      "        True\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        Solution of sparse indefinite systems of linear equations,\n",
      "            C. C. Paige and M. A. Saunders (1975),\n",
      "            SIAM J. Numer. Anal. 12(4), pp. 617-629.\n",
      "            https://web.stanford.edu/group/SOL/software/minres/\n",
      "        \n",
      "        This file is a translation of the following MATLAB implementation:\n",
      "            https://web.stanford.edu/group/SOL/software/minres/minres-matlab.zip\n",
      "    \n",
      "    norm(x, ord=None, axis=None)\n",
      "        Norm of a sparse matrix\n",
      "        \n",
      "        This function is able to return one of seven different matrix norms,\n",
      "        depending on the value of the ``ord`` parameter.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : a sparse matrix\n",
      "            Input sparse matrix.\n",
      "        ord : {non-zero int, inf, -inf, 'fro'}, optional\n",
      "            Order of the norm (see table under ``Notes``). inf means numpy's\n",
      "            `inf` object.\n",
      "        axis : {int, 2-tuple of ints, None}, optional\n",
      "            If `axis` is an integer, it specifies the axis of `x` along which to\n",
      "            compute the vector norms.  If `axis` is a 2-tuple, it specifies the\n",
      "            axes that hold 2-D matrices, and the matrix norms of these matrices\n",
      "            are computed.  If `axis` is None then either a vector norm (when `x`\n",
      "            is 1-D) or a matrix norm (when `x` is 2-D) is returned.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        n : float or ndarray\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Some of the ord are not implemented because some associated functions like,\n",
      "        _multi_svd_norm, are not yet available for sparse matrix.\n",
      "        \n",
      "        This docstring is modified based on numpy.linalg.norm.\n",
      "        https://github.com/numpy/numpy/blob/main/numpy/linalg/linalg.py\n",
      "        \n",
      "        The following norms can be calculated:\n",
      "        \n",
      "        =====  ============================\n",
      "        ord    norm for sparse matrices\n",
      "        =====  ============================\n",
      "        None   Frobenius norm\n",
      "        'fro'  Frobenius norm\n",
      "        inf    max(sum(abs(x), axis=1))\n",
      "        -inf   min(sum(abs(x), axis=1))\n",
      "        0      abs(x).sum(axis=axis)\n",
      "        1      max(sum(abs(x), axis=0))\n",
      "        -1     min(sum(abs(x), axis=0))\n",
      "        2      Not implemented\n",
      "        -2     Not implemented\n",
      "        other  Not implemented\n",
      "        =====  ============================\n",
      "        \n",
      "        The Frobenius norm is given by [1]_:\n",
      "        \n",
      "            :math:`||A||_F = [\\sum_{i,j} abs(a_{i,j})^2]^{1/2}`\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] G. H. Golub and C. F. Van Loan, *Matrix Computations*,\n",
      "            Baltimore, MD, Johns Hopkins University Press, 1985, pg. 15\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import *\n",
      "        >>> import numpy as np\n",
      "        >>> from scipy.sparse.linalg import norm\n",
      "        >>> a = np.arange(9) - 4\n",
      "        >>> a\n",
      "        array([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
      "        >>> b = a.reshape((3, 3))\n",
      "        >>> b\n",
      "        array([[-4, -3, -2],\n",
      "               [-1, 0, 1],\n",
      "               [ 2, 3, 4]])\n",
      "        \n",
      "        >>> b = csr_matrix(b)\n",
      "        >>> norm(b)\n",
      "        7.745966692414834\n",
      "        >>> norm(b, 'fro')\n",
      "        7.745966692414834\n",
      "        >>> norm(b, np.inf)\n",
      "        9\n",
      "        >>> norm(b, -np.inf)\n",
      "        2\n",
      "        >>> norm(b, 1)\n",
      "        7\n",
      "        >>> norm(b, -1)\n",
      "        6\n",
      "    \n",
      "    onenormest(A, t=2, itmax=5, compute_v=False, compute_w=False)\n",
      "        Compute a lower bound of the 1-norm of a sparse matrix.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : ndarray or other linear operator\n",
      "            A linear operator that can be transposed and that can\n",
      "            produce matrix products.\n",
      "        t : int, optional\n",
      "            A positive parameter controlling the tradeoff between\n",
      "            accuracy versus time and memory usage.\n",
      "            Larger values take longer and use more memory\n",
      "            but give more accurate output.\n",
      "        itmax : int, optional\n",
      "            Use at most this many iterations.\n",
      "        compute_v : bool, optional\n",
      "            Request a norm-maximizing linear operator input vector if True.\n",
      "        compute_w : bool, optional\n",
      "            Request a norm-maximizing linear operator output vector if True.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        est : float\n",
      "            An underestimate of the 1-norm of the sparse matrix.\n",
      "        v : ndarray, optional\n",
      "            The vector such that ||Av||_1 == est*||v||_1.\n",
      "            It can be thought of as an input to the linear operator\n",
      "            that gives an output with particularly large norm.\n",
      "        w : ndarray, optional\n",
      "            The vector Av which has relatively large 1-norm.\n",
      "            It can be thought of as an output of the linear operator\n",
      "            that is relatively large in norm compared to the input.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This is algorithm 2.4 of [1].\n",
      "        \n",
      "        In [2] it is described as follows.\n",
      "        \"This algorithm typically requires the evaluation of\n",
      "        about 4t matrix-vector products and almost invariably\n",
      "        produces a norm estimate (which is, in fact, a lower\n",
      "        bound on the norm) correct to within a factor 3.\"\n",
      "        \n",
      "        .. versionadded:: 0.13.0\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Nicholas J. Higham and Francoise Tisseur (2000),\n",
      "               \"A Block Algorithm for Matrix 1-Norm Estimation,\n",
      "               with an Application to 1-Norm Pseudospectra.\"\n",
      "               SIAM J. Matrix Anal. Appl. Vol. 21, No. 4, pp. 1185-1201.\n",
      "        \n",
      "        .. [2] Awad H. Al-Mohy and Nicholas J. Higham (2009),\n",
      "               \"A new scaling and squaring algorithm for the matrix exponential.\"\n",
      "               SIAM J. Matrix Anal. Appl. Vol. 31, No. 3, pp. 970-989.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import onenormest\n",
      "        >>> A = csc_matrix([[1., 0., 0.], [5., 8., 2.], [0., -1., 0.]], dtype=float)\n",
      "        >>> A.toarray()\n",
      "        array([[ 1.,  0.,  0.],\n",
      "               [ 5.,  8.,  2.],\n",
      "               [ 0., -1.,  0.]])\n",
      "        >>> onenormest(A)\n",
      "        9.0\n",
      "        >>> np.linalg.norm(A.toarray(), ord=1)\n",
      "        9.0\n",
      "    \n",
      "    qmr(A, b, x0=None, tol=1e-05, maxiter=None, M1=None, M2=None, callback=None, atol=None)\n",
      "        Use Quasi-Minimal Residual iteration to solve ``Ax = b``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, ndarray, LinearOperator}\n",
      "            The real-valued N-by-N matrix of the linear system.\n",
      "            Alternatively, ``A`` can be a linear operator which can\n",
      "            produce ``Ax`` and ``A^T x`` using, e.g.,\n",
      "            ``scipy.sparse.linalg.LinearOperator``.\n",
      "        b : ndarray\n",
      "            Right hand side of the linear system. Has shape (N,) or (N,1).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : ndarray\n",
      "            The converged solution.\n",
      "        info : integer\n",
      "            Provides convergence information:\n",
      "                0  : successful exit\n",
      "                >0 : convergence to tolerance not achieved, number of iterations\n",
      "                <0 : illegal input or breakdown\n",
      "        \n",
      "        Other Parameters\n",
      "        ----------------\n",
      "        x0 : ndarray\n",
      "            Starting guess for the solution.\n",
      "        tol, atol : float, optional\n",
      "            Tolerances for convergence, ``norm(residual) <= max(tol*norm(b), atol)``.\n",
      "            The default for ``atol`` is ``'legacy'``, which emulates\n",
      "            a different legacy behavior.\n",
      "        \n",
      "            .. warning::\n",
      "        \n",
      "               The default value for `atol` will be changed in a future release.\n",
      "               For future compatibility, specify `atol` explicitly.\n",
      "        maxiter : integer\n",
      "            Maximum number of iterations.  Iteration will stop after maxiter\n",
      "            steps even if the specified tolerance has not been achieved.\n",
      "        M1 : {sparse matrix, ndarray, LinearOperator}\n",
      "            Left preconditioner for A.\n",
      "        M2 : {sparse matrix, ndarray, LinearOperator}\n",
      "            Right preconditioner for A. Used together with the left\n",
      "            preconditioner M1.  The matrix M1@A@M2 should have better\n",
      "            conditioned than A alone.\n",
      "        callback : function\n",
      "            User-supplied function to call after each iteration.  It is called\n",
      "            as callback(xk), where xk is the current solution vector.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        LinearOperator\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import qmr\n",
      "        >>> A = csc_matrix([[3, 2, 0], [1, -1, 0], [0, 5, 1]], dtype=float)\n",
      "        >>> b = np.array([2, 4, -1], dtype=float)\n",
      "        >>> x, exitCode = qmr(A, b)\n",
      "        >>> print(exitCode)            # 0 indicates successful convergence\n",
      "        0\n",
      "        >>> np.allclose(A.dot(x), b)\n",
      "        True\n",
      "    \n",
      "    spilu(A, drop_tol=None, fill_factor=None, drop_rule=None, permc_spec=None, diag_pivot_thresh=None, relax=None, panel_size=None, options=None)\n",
      "        Compute an incomplete LU decomposition for a sparse, square matrix.\n",
      "        \n",
      "        The resulting object is an approximation to the inverse of `A`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : (N, N) array_like\n",
      "            Sparse matrix to factorize. Most efficient when provided in CSC format.\n",
      "            Other formats will be converted to CSC before factorization.\n",
      "        drop_tol : float, optional\n",
      "            Drop tolerance (0 <= tol <= 1) for an incomplete LU decomposition.\n",
      "            (default: 1e-4)\n",
      "        fill_factor : float, optional\n",
      "            Specifies the fill ratio upper bound (>= 1.0) for ILU. (default: 10)\n",
      "        drop_rule : str, optional\n",
      "            Comma-separated string of drop rules to use.\n",
      "            Available rules: ``basic``, ``prows``, ``column``, ``area``,\n",
      "            ``secondary``, ``dynamic``, ``interp``. (Default: ``basic,area``)\n",
      "        \n",
      "            See SuperLU documentation for details.\n",
      "        \n",
      "        Remaining other options\n",
      "            Same as for `splu`\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        invA_approx : scipy.sparse.linalg.SuperLU\n",
      "            Object, which has a ``solve`` method.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        splu : complete LU decomposition\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        To improve the better approximation to the inverse, you may need to\n",
      "        increase `fill_factor` AND decrease `drop_tol`.\n",
      "        \n",
      "        This function uses the SuperLU library.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import spilu\n",
      "        >>> A = csc_matrix([[1., 0., 0.], [5., 0., 2.], [0., -1., 0.]], dtype=float)\n",
      "        >>> B = spilu(A)\n",
      "        >>> x = np.array([1., 2., 3.], dtype=float)\n",
      "        >>> B.solve(x)\n",
      "        array([ 1. , -3. , -1.5])\n",
      "        >>> A.dot(B.solve(x))\n",
      "        array([ 1.,  2.,  3.])\n",
      "        >>> B.solve(A.dot(x))\n",
      "        array([ 1.,  2.,  3.])\n",
      "    \n",
      "    splu(A, permc_spec=None, diag_pivot_thresh=None, relax=None, panel_size=None, options={})\n",
      "        Compute the LU decomposition of a sparse, square matrix.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : sparse matrix\n",
      "            Sparse matrix to factorize. Most efficient when provided in CSC\n",
      "            format. Other formats will be converted to CSC before factorization.\n",
      "        permc_spec : str, optional\n",
      "            How to permute the columns of the matrix for sparsity preservation.\n",
      "            (default: 'COLAMD')\n",
      "        \n",
      "            - ``NATURAL``: natural ordering.\n",
      "            - ``MMD_ATA``: minimum degree ordering on the structure of A^T A.\n",
      "            - ``MMD_AT_PLUS_A``: minimum degree ordering on the structure of A^T+A.\n",
      "            - ``COLAMD``: approximate minimum degree column ordering\n",
      "        \n",
      "        diag_pivot_thresh : float, optional\n",
      "            Threshold used for a diagonal entry to be an acceptable pivot.\n",
      "            See SuperLU user's guide for details [1]_\n",
      "        relax : int, optional\n",
      "            Expert option for customizing the degree of relaxing supernodes.\n",
      "            See SuperLU user's guide for details [1]_\n",
      "        panel_size : int, optional\n",
      "            Expert option for customizing the panel size.\n",
      "            See SuperLU user's guide for details [1]_\n",
      "        options : dict, optional\n",
      "            Dictionary containing additional expert options to SuperLU.\n",
      "            See SuperLU user guide [1]_ (section 2.4 on the 'Options' argument)\n",
      "            for more details. For example, you can specify\n",
      "            ``options=dict(Equil=False, IterRefine='SINGLE'))``\n",
      "            to turn equilibration off and perform a single iterative refinement.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        invA : scipy.sparse.linalg.SuperLU\n",
      "            Object, which has a ``solve`` method.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        spilu : incomplete LU decomposition\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This function uses the SuperLU library.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] SuperLU https://portal.nersc.gov/project/sparse/superlu/\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import splu\n",
      "        >>> A = csc_matrix([[1., 0., 0.], [5., 0., 2.], [0., -1., 0.]], dtype=float)\n",
      "        >>> B = splu(A)\n",
      "        >>> x = np.array([1., 2., 3.], dtype=float)\n",
      "        >>> B.solve(x)\n",
      "        array([ 1. , -3. , -1.5])\n",
      "        >>> A.dot(B.solve(x))\n",
      "        array([ 1.,  2.,  3.])\n",
      "        >>> B.solve(A.dot(x))\n",
      "        array([ 1.,  2.,  3.])\n",
      "    \n",
      "    spsolve(A, b, permc_spec=None, use_umfpack=True)\n",
      "        Solve the sparse linear system Ax=b, where b may be a vector or a matrix.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : ndarray or sparse matrix\n",
      "            The square matrix A will be converted into CSC or CSR form\n",
      "        b : ndarray or sparse matrix\n",
      "            The matrix or vector representing the right hand side of the equation.\n",
      "            If a vector, b.shape must be (n,) or (n, 1).\n",
      "        permc_spec : str, optional\n",
      "            How to permute the columns of the matrix for sparsity preservation.\n",
      "            (default: 'COLAMD')\n",
      "        \n",
      "            - ``NATURAL``: natural ordering.\n",
      "            - ``MMD_ATA``: minimum degree ordering on the structure of A^T A.\n",
      "            - ``MMD_AT_PLUS_A``: minimum degree ordering on the structure of A^T+A.\n",
      "            - ``COLAMD``: approximate minimum degree column ordering [1]_, [2]_.\n",
      "        \n",
      "        use_umfpack : bool, optional\n",
      "            if True (default) then use umfpack for the solution.  This is\n",
      "            only referenced if b is a vector and ``scikit-umfpack`` is installed.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : ndarray or sparse matrix\n",
      "            the solution of the sparse linear equation.\n",
      "            If b is a vector, then x is a vector of size A.shape[1]\n",
      "            If b is a matrix, then x is a matrix of size (A.shape[1], b.shape[1])\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        For solving the matrix expression AX = B, this solver assumes the resulting\n",
      "        matrix X is sparse, as is often the case for very sparse inputs.  If the\n",
      "        resulting X is dense, the construction of this sparse result will be\n",
      "        relatively expensive.  In that case, consider converting A to a dense\n",
      "        matrix and using scipy.linalg.solve or its variants.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] T. A. Davis, J. R. Gilbert, S. Larimore, E. Ng, Algorithm 836:\n",
      "               COLAMD, an approximate column minimum degree ordering algorithm,\n",
      "               ACM Trans. on Mathematical Software, 30(3), 2004, pp. 377--380.\n",
      "               :doi:`10.1145/1024074.1024080`\n",
      "        \n",
      "        .. [2] T. A. Davis, J. R. Gilbert, S. Larimore, E. Ng, A column approximate\n",
      "               minimum degree ordering algorithm, ACM Trans. on Mathematical\n",
      "               Software, 30(3), 2004, pp. 353--376. :doi:`10.1145/1024074.1024079`\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import spsolve\n",
      "        >>> A = csc_matrix([[3, 2, 0], [1, -1, 0], [0, 5, 1]], dtype=float)\n",
      "        >>> B = csc_matrix([[2, 0], [-1, 0], [2, 0]], dtype=float)\n",
      "        >>> x = spsolve(A, B)\n",
      "        >>> np.allclose(A.dot(x).toarray(), B.toarray())\n",
      "        True\n",
      "    \n",
      "    spsolve_triangular(A, b, lower=True, overwrite_A=False, overwrite_b=False, unit_diagonal=False)\n",
      "        Solve the equation ``A x = b`` for `x`, assuming A is a triangular matrix.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : (M, M) sparse matrix\n",
      "            A sparse square triangular matrix. Should be in CSR format.\n",
      "        b : (M,) or (M, N) array_like\n",
      "            Right-hand side matrix in ``A x = b``\n",
      "        lower : bool, optional\n",
      "            Whether `A` is a lower or upper triangular matrix.\n",
      "            Default is lower triangular matrix.\n",
      "        overwrite_A : bool, optional\n",
      "            Allow changing `A`. The indices of `A` are going to be sorted and zero\n",
      "            entries are going to be removed.\n",
      "            Enabling gives a performance gain. Default is False.\n",
      "        overwrite_b : bool, optional\n",
      "            Allow overwriting data in `b`.\n",
      "            Enabling gives a performance gain. Default is False.\n",
      "            If `overwrite_b` is True, it should be ensured that\n",
      "            `b` has an appropriate dtype to be able to store the result.\n",
      "        unit_diagonal : bool, optional\n",
      "            If True, diagonal elements of `a` are assumed to be 1 and will not be\n",
      "            referenced.\n",
      "        \n",
      "            .. versionadded:: 1.4.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : (M,) or (M, N) ndarray\n",
      "            Solution to the system ``A x = b``. Shape of return matches shape\n",
      "            of `b`.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If `A` is singular or not triangular.\n",
      "        ValueError\n",
      "            If shape of `A` or shape of `b` do not match the requirements.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        .. versionadded:: 0.19.0\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csr_matrix\n",
      "        >>> from scipy.sparse.linalg import spsolve_triangular\n",
      "        >>> A = csr_matrix([[3, 0, 0], [1, -1, 0], [2, 0, 1]], dtype=float)\n",
      "        >>> B = np.array([[2, 0], [-1, 0], [2, 0]], dtype=float)\n",
      "        >>> x = spsolve_triangular(A, B)\n",
      "        >>> np.allclose(A.dot(x), B)\n",
      "        True\n",
      "    \n",
      "    svds(A, k=6, ncv=None, tol=0, which='LM', v0=None, maxiter=None, return_singular_vectors=True, solver='arpack', random_state=None, options=None)\n",
      "        Partial singular value decomposition of a sparse matrix.\n",
      "        \n",
      "        Compute the largest or smallest `k` singular values and corresponding\n",
      "        singular vectors of a sparse matrix `A`. The order in which the singular\n",
      "        values are returned is not guaranteed.\n",
      "        \n",
      "        In the descriptions below, let ``M, N = A.shape``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : ndarray, sparse matrix, or LinearOperator\n",
      "            Matrix to decompose of a floating point numeric dtype.\n",
      "        k : int, default: 6\n",
      "            Number of singular values and singular vectors to compute.\n",
      "            Must satisfy ``1 <= k <= kmax``, where ``kmax=min(M, N)`` for\n",
      "            ``solver='propack'`` and ``kmax=min(M, N) - 1`` otherwise.\n",
      "        ncv : int, optional\n",
      "            When ``solver='arpack'``, this is the number of Lanczos vectors\n",
      "            generated. See :ref:`'arpack' <sparse.linalg.svds-arpack>` for details.\n",
      "            When ``solver='lobpcg'`` or ``solver='propack'``, this parameter is\n",
      "            ignored.\n",
      "        tol : float, optional\n",
      "            Tolerance for singular values. Zero (default) means machine precision.\n",
      "        which : {'LM', 'SM'}\n",
      "            Which `k` singular values to find: either the largest magnitude ('LM')\n",
      "            or smallest magnitude ('SM') singular values.\n",
      "        v0 : ndarray, optional\n",
      "            The starting vector for iteration; see method-specific\n",
      "            documentation (:ref:`'arpack' <sparse.linalg.svds-arpack>`,\n",
      "            :ref:`'lobpcg' <sparse.linalg.svds-lobpcg>`), or\n",
      "            :ref:`'propack' <sparse.linalg.svds-propack>` for details.\n",
      "        maxiter : int, optional\n",
      "            Maximum number of iterations; see method-specific\n",
      "            documentation (:ref:`'arpack' <sparse.linalg.svds-arpack>`,\n",
      "            :ref:`'lobpcg' <sparse.linalg.svds-lobpcg>`), or\n",
      "            :ref:`'propack' <sparse.linalg.svds-propack>` for details.\n",
      "        return_singular_vectors : {True, False, \"u\", \"vh\"}\n",
      "            Singular values are always computed and returned; this parameter\n",
      "            controls the computation and return of singular vectors.\n",
      "        \n",
      "            - ``True``: return singular vectors.\n",
      "            - ``False``: do not return singular vectors.\n",
      "            - ``\"u\"``: if ``M <= N``, compute only the left singular vectors and\n",
      "              return ``None`` for the right singular vectors. Otherwise, compute\n",
      "              all singular vectors.\n",
      "            - ``\"vh\"``: if ``M > N``, compute only the right singular vectors and\n",
      "              return ``None`` for the left singular vectors. Otherwise, compute\n",
      "              all singular vectors.\n",
      "        \n",
      "            If ``solver='propack'``, the option is respected regardless of the\n",
      "            matrix shape.\n",
      "        \n",
      "        solver :  {'arpack', 'propack', 'lobpcg'}, optional\n",
      "                The solver used.\n",
      "                :ref:`'arpack' <sparse.linalg.svds-arpack>`,\n",
      "                :ref:`'lobpcg' <sparse.linalg.svds-lobpcg>`, and\n",
      "                :ref:`'propack' <sparse.linalg.svds-propack>` are supported.\n",
      "                Default: `'arpack'`.\n",
      "        random_state : {None, int, `numpy.random.Generator`,\n",
      "                        `numpy.random.RandomState`}, optional\n",
      "        \n",
      "            Pseudorandom number generator state used to generate resamples.\n",
      "        \n",
      "            If `random_state` is ``None`` (or `np.random`), the\n",
      "            `numpy.random.RandomState` singleton is used.\n",
      "            If `random_state` is an int, a new ``RandomState`` instance is used,\n",
      "            seeded with `random_state`.\n",
      "            If `random_state` is already a ``Generator`` or ``RandomState``\n",
      "            instance then that instance is used.\n",
      "        options : dict, optional\n",
      "            A dictionary of solver-specific options. No solver-specific options\n",
      "            are currently supported; this parameter is reserved for future use.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        u : ndarray, shape=(M, k)\n",
      "            Unitary matrix having left singular vectors as columns.\n",
      "        s : ndarray, shape=(k,)\n",
      "            The singular values.\n",
      "        vh : ndarray, shape=(k, N)\n",
      "            Unitary matrix having right singular vectors as rows.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This is a naive implementation using ARPACK or LOBPCG as an eigensolver\n",
      "        on ``A.conj().T @ A`` or ``A @ A.conj().T``, depending on which one is more\n",
      "        efficient, followed by the Rayleigh-Ritz method as postprocessing; see\n",
      "        https://w.wiki/4zms\n",
      "        \n",
      "        Alternatively, the PROPACK solver can be called. ``form=\"array\"``\n",
      "        \n",
      "        Choices of the input matrix ``A`` numeric dtype may be limited.\n",
      "        Only ``solver=\"lobpcg\"`` supports all floating point dtypes\n",
      "        real: 'np.single', 'np.double', 'np.longdouble' and\n",
      "        complex: 'np.csingle', 'np.cdouble', 'np.clongdouble'.\n",
      "        The ``solver=\"arpack\"`` supports only\n",
      "        'np.single', 'np.double', and 'np.cdouble'.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Construct a matrix ``A`` from singular values and vectors.\n",
      "        \n",
      "        >>> from scipy.stats import ortho_group\n",
      "        >>> from scipy.sparse import csc_matrix, diags\n",
      "        >>> from scipy.sparse.linalg import svds\n",
      "        >>> rng = np.random.default_rng()\n",
      "        >>> orthogonal = csc_matrix(ortho_group.rvs(10, random_state=rng))\n",
      "        >>> s = [0.0001, 0.001, 3, 4, 5]  # singular values\n",
      "        >>> u = orthogonal[:, :5]         # left singular vectors\n",
      "        >>> vT = orthogonal[:, 5:].T      # right singular vectors\n",
      "        >>> A = u @ diags(s) @ vT\n",
      "        \n",
      "        With only three singular values/vectors, the SVD approximates the original\n",
      "        matrix.\n",
      "        \n",
      "        >>> u2, s2, vT2 = svds(A, k=3)\n",
      "        >>> A2 = u2 @ np.diag(s2) @ vT2\n",
      "        >>> np.allclose(A2, A.toarray(), atol=1e-3)\n",
      "        True\n",
      "        \n",
      "        With all five singular values/vectors, we can reproduce the original\n",
      "        matrix.\n",
      "        \n",
      "        >>> u3, s3, vT3 = svds(A, k=5)\n",
      "        >>> A3 = u3 @ np.diag(s3) @ vT3\n",
      "        >>> np.allclose(A3, A.toarray())\n",
      "        True\n",
      "        \n",
      "        The singular values match the expected singular values, and the singular\n",
      "        vectors are as expected up to a difference in sign.\n",
      "        \n",
      "        >>> (np.allclose(s3, s) and\n",
      "        ...  np.allclose(np.abs(u3), np.abs(u.toarray())) and\n",
      "        ...  np.allclose(np.abs(vT3), np.abs(vT.toarray())))\n",
      "        True\n",
      "        \n",
      "        The singular vectors are also orthogonal.\n",
      "        >>> (np.allclose(u3.T @ u3, np.eye(5)) and\n",
      "        ...  np.allclose(vT3 @ vT3.T, np.eye(5)))\n",
      "        True\n",
      "    \n",
      "    tfqmr(A, b, x0=None, tol=1e-05, maxiter=None, M=None, callback=None, atol=None, show=False)\n",
      "        Use Transpose-Free Quasi-Minimal Residual iteration to solve ``Ax = b``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        A : {sparse matrix, ndarray, LinearOperator}\n",
      "            The real or complex N-by-N matrix of the linear system.\n",
      "            Alternatively, `A` can be a linear operator which can\n",
      "            produce ``Ax`` using, e.g.,\n",
      "            `scipy.sparse.linalg.LinearOperator`.\n",
      "        b : {ndarray}\n",
      "            Right hand side of the linear system. Has shape (N,) or (N,1).\n",
      "        x0 : {ndarray}\n",
      "            Starting guess for the solution.\n",
      "        tol, atol : float, optional\n",
      "            Tolerances for convergence, ``norm(residual) <= max(tol*norm(b-Ax0), atol)``.\n",
      "            The default for `tol` is 1.0e-5.\n",
      "            The default for `atol` is ``tol * norm(b-Ax0)``.\n",
      "        \n",
      "            .. warning::\n",
      "        \n",
      "               The default value for `atol` will be changed in a future release.\n",
      "               For future compatibility, specify `atol` explicitly.\n",
      "        maxiter : int, optional\n",
      "            Maximum number of iterations.  Iteration will stop after maxiter\n",
      "            steps even if the specified tolerance has not been achieved.\n",
      "            Default is ``min(10000, ndofs * 10)``, where ``ndofs = A.shape[0]``.\n",
      "        M : {sparse matrix, ndarray, LinearOperator}\n",
      "            Inverse of the preconditioner of A.  M should approximate the\n",
      "            inverse of A and be easy to solve for (see Notes).  Effective\n",
      "            preconditioning dramatically improves the rate of convergence,\n",
      "            which implies that fewer iterations are needed to reach a given\n",
      "            error tolerance.  By default, no preconditioner is used.\n",
      "        callback : function, optional\n",
      "            User-supplied function to call after each iteration.  It is called\n",
      "            as `callback(xk)`, where `xk` is the current solution vector.\n",
      "        show : bool, optional\n",
      "            Specify ``show = True`` to show the convergence, ``show = False`` is\n",
      "            to close the output of the convergence.\n",
      "            Default is `False`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : ndarray\n",
      "            The converged solution.\n",
      "        info : int\n",
      "            Provides convergence information:\n",
      "        \n",
      "                - 0  : successful exit\n",
      "                - >0 : convergence to tolerance not achieved, number of iterations\n",
      "                - <0 : illegal input or breakdown\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The Transpose-Free QMR algorithm is derived from the CGS algorithm.\n",
      "        However, unlike CGS, the convergence curves for the TFQMR method is\n",
      "        smoothed by computing a quasi minimization of the residual norm. The\n",
      "        implementation supports left preconditioner, and the \"residual norm\"\n",
      "        to compute in convergence criterion is actually an upper bound on the\n",
      "        actual residual norm ``||b - Axk||``.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] R. W. Freund, A Transpose-Free Quasi-Minimal Residual Algorithm for\n",
      "               Non-Hermitian Linear Systems, SIAM J. Sci. Comput., 14(2), 470-482,\n",
      "               1993.\n",
      "        .. [2] Y. Saad, Iterative Methods for Sparse Linear Systems, 2nd edition,\n",
      "               SIAM, Philadelphia, 2003.\n",
      "        .. [3] C. T. Kelley, Iterative Methods for Linear and Nonlinear Equations,\n",
      "               number 16 in Frontiers in Applied Mathematics, SIAM, Philadelphia,\n",
      "               1995.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> from scipy.sparse.linalg import tfqmr\n",
      "        >>> A = csc_matrix([[3, 2, 0], [1, -1, 0], [0, 5, 1]], dtype=float)\n",
      "        >>> b = np.array([2, 4, -1], dtype=float)\n",
      "        >>> x, exitCode = tfqmr(A, b)\n",
      "        >>> print(exitCode)            # 0 indicates successful convergence\n",
      "        0\n",
      "        >>> np.allclose(A.dot(x), b)\n",
      "        True\n",
      "    \n",
      "    use_solver(**kwargs)\n",
      "        Select default sparse direct solver to be used.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        useUmfpack : bool, optional\n",
      "            Use UMFPACK over SuperLU. Has effect only if scikits.umfpack is\n",
      "            installed. Default: True\n",
      "        assumeSortedIndices : bool, optional\n",
      "            Allow UMFPACK to skip the step of sorting indices for a CSR/CSC matrix.\n",
      "            Has effect only if useUmfpack is True and scikits.umfpack is installed.\n",
      "            Default: False\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The default sparse solver is umfpack when available\n",
      "        (scikits.umfpack is installed). This can be changed by passing\n",
      "        useUmfpack = False, which then causes the always present SuperLU\n",
      "        based solver to be used.\n",
      "        \n",
      "        Umfpack requires a CSR/CSC matrix to have sorted column/row indices. If\n",
      "        sure that the matrix fulfills this, pass ``assumeSortedIndices=True``\n",
      "        to gain some speed.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.sparse.linalg import use_solver, spsolve\n",
      "        >>> from scipy.sparse import csc_matrix\n",
      "        >>> R = np.random.randn(5, 5)\n",
      "        >>> A = csc_matrix(R)\n",
      "        >>> b = np.random.randn(5)\n",
      "        >>> use_solver(useUmfpack=False) # enforce superLU over UMFPACK\n",
      "        >>> x = spsolve(A, b)\n",
      "        >>> np.allclose(A.dot(x), b)\n",
      "        True\n",
      "        >>> use_solver(useUmfpack=True) # reset umfPack usage to default\n",
      "\n",
      "DATA\n",
      "    __all__ = ['ArpackError', 'ArpackNoConvergence', 'LinearOperator', 'Ma...\n",
      "\n",
      "FILE\n",
      "    /home/husnain/Desktop/RandomProjects/100-Digit-Challenge/venv/lib/python3.10/site-packages/scipy/sparse/linalg/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse.linalg as linalg\n",
    "help(linalg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10: current val = 0.19423089190652099\n",
      "Iteration 20: current val = 0.23417992806110038\n",
      "Iteration 30: current val = 0.2656958595038305\n",
      "Iteration 40: current val = 0.3054222707982813\n",
      "Iteration 50: current val = 0.3135587933679594\n",
      "Iteration 60: current val = 0.3556327670184943\n",
      "Iteration 70: current val = 0.3789918731142482\n",
      "Iteration 80: current val = 0.38544876096001984\n",
      "Iteration 90: current val = 0.4121182251863883\n",
      "Iteration 100: current val = 0.44925068976200094\n",
      "Iteration 110: current val = 0.475242867281242\n",
      "Iteration 120: current val = 0.4816244852405636\n",
      "Iteration 130: current val = 0.4902349361021055\n",
      "Iteration 140: current val = 0.49962816500256785\n",
      "Iteration 150: current val = 0.5174883308803532\n",
      "Iteration 160: current val = 0.5488219155722759\n",
      "Iteration 170: current val = 0.5773560934837708\n",
      "Iteration 180: current val = 0.5899200677253085\n",
      "Iteration 190: current val = 0.6001837437958351\n",
      "Iteration 200: current val = 0.6084965638571498\n",
      "Iteration 210: current val = 0.614470981569122\n",
      "Iteration 220: current val = 0.6201437214776055\n",
      "Iteration 230: current val = 0.6265843254624347\n",
      "Iteration 240: current val = 0.6342895899924987\n",
      "Iteration 250: current val = 0.645769400235154\n",
      "Iteration 260: current val = 0.6580541170354327\n",
      "Iteration 270: current val = 0.6652304556209694\n",
      "Iteration 280: current val = 0.6715354989635203\n",
      "Iteration 290: current val = 0.679351873615647\n",
      "Iteration 300: current val = 0.6851335281949464\n",
      "Iteration 310: current val = 0.6905904408856288\n",
      "Iteration 320: current val = 0.6941412188936459\n",
      "Iteration 330: current val = 0.6967504095675519\n",
      "Iteration 340: current val = 0.698280415296723\n",
      "Iteration 350: current val = 0.7003302973496128\n",
      "Iteration 360: current val = 0.7015820063410101\n",
      "Iteration 370: current val = 0.703077119238208\n",
      "Iteration 380: current val = 0.7042667951785331\n",
      "Iteration 390: current val = 0.7060330392471759\n",
      "Iteration 400: current val = 0.7076320809582473\n",
      "Iteration 410: current val = 0.7088733093280405\n",
      "Iteration 420: current val = 0.7099046410843219\n",
      "Iteration 430: current val = 0.7108280723664253\n",
      "Iteration 440: current val = 0.7122709444884214\n",
      "Iteration 450: current val = 0.7133368882565503\n",
      "Iteration 460: current val = 0.7151733896244761\n",
      "Iteration 470: current val = 0.7164532077115987\n",
      "Iteration 480: current val = 0.7176067323351487\n",
      "Iteration 490: current val = 0.7187577499162386\n",
      "Iteration 500: current val = 0.7200610611530582\n",
      "Iteration 510: current val = 0.7207722125486876\n",
      "Iteration 520: current val = 0.7212670690802756\n",
      "Iteration 530: current val = 0.721858877106239\n",
      "Iteration 540: current val = 0.7224113129560623\n",
      "Iteration 550: current val = 0.7227338584414432\n",
      "Iteration 560: current val = 0.7230904209673094\n",
      "Iteration 570: current val = 0.7234119794836257\n",
      "Iteration 580: current val = 0.7236040430793119\n",
      "Iteration 590: current val = 0.7238214468875199\n",
      "Iteration 600: current val = 0.7240704926461214\n",
      "Iteration 610: current val = 0.7242487564826274\n",
      "Iteration 620: current val = 0.7244048211244024\n",
      "Iteration 630: current val = 0.724563040327154\n",
      "Iteration 640: current val = 0.7246756683882029\n",
      "Iteration 650: current val = 0.7247529455811774\n",
      "Iteration 660: current val = 0.724822998098779\n",
      "Iteration 670: current val = 0.7248756382983441\n",
      "Iteration 680: current val = 0.7248987895043125\n",
      "Iteration 690: current val = 0.7249198852175985\n",
      "Iteration 700: current val = 0.7249408117752596\n",
      "Iteration 710: current val = 0.7249622919688695\n",
      "Iteration 720: current val = 0.7249825815203575\n",
      "Iteration 730: current val = 0.7249973681726765\n",
      "Iteration 740: current val = 0.7250075636881783\n",
      "Iteration 750: current val = 0.7250186759469228\n",
      "Iteration 760: current val = 0.7250290730685494\n",
      "Iteration 770: current val = 0.7250395349713696\n",
      "Iteration 780: current val = 0.7250487251706257\n",
      "Iteration 790: current val = 0.7250552028554459\n",
      "Iteration 800: current val = 0.7250600524551658\n",
      "Iteration 810: current val = 0.7250638615657787\n",
      "Iteration 820: current val = 0.7250670734366101\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, Y = [], []\n",
    "\n",
    "iterations = 0\n",
    "def callback(xk):\n",
    "    global iterations, X, Y\n",
    "    iterations += 1\n",
    "    X.append(iterations); Y.append(xk[0])\n",
    "    if iterations % 10 == 0: print(\"Iteration {}: current val = {}\".format(iterations, xk[0]))\n",
    "\n",
    "linalg.qmr(A, b, callback=callback)\n",
    "\n",
    "plt.plot(X, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPEr5R+vBWEUgLKt8e+FhsB",
   "name": "Problem 7",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
